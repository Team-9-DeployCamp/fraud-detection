# Fraud Detection System

A complete machine learning system for credit card fraud detection using MLflow for model tracking and FastAPI for serving predictions.

## ğŸ—ï¸ Project Structure

```
fraud_detection/
â”œâ”€â”€ ğŸ“ src/                     # Source code
â”‚   â”œâ”€â”€ api.py                  # FastAPI application
â”‚   â”œâ”€â”€ inference.py            # Model inference logic
â”‚   â”œâ”€â”€ preprocess.py           # Data preprocessing
â”‚   â”œâ”€â”€ train.py                # Model training
â”‚   â””â”€â”€ util.py                 # Utility functions
â”œâ”€â”€ ğŸ“ deployment/              # Docker deployment files
â”‚   â”œâ”€â”€ docker-compose.yml     # Multi-service orchestration
â”‚   â”œâ”€â”€ Dockerfile.api          # API service container
â”‚   â”œâ”€â”€ Dockerfile.mlflow       # MLflow server container
â”‚   â”œâ”€â”€ Dockerfile              # Standalone API container
â”‚   â””â”€â”€ .dockerignore           # Docker ignore rules
â”œâ”€â”€ ğŸ“ scripts/                 # Management and utility scripts
â”‚   â”œâ”€â”€ manage.ps1              # PowerShell management script
â”‚   â”œâ”€â”€ manage.sh               # Bash management script
â”‚   â”œâ”€â”€ run_pipeline.py         # ML pipeline runner
â”‚   â”œâ”€â”€ test_api.py             # API testing script
â”‚   â””â”€â”€ test_docker_services.py # Docker services test
â”œâ”€â”€ ğŸ“ configs/                 # Configuration files
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ config.yaml         # Main configuration
â”‚   â”‚   â””â”€â”€ config.docker.yaml  # Docker-specific config
â”‚   â”œâ”€â”€ dt_tuned_params.json    # Decision Tree hyperparameters
â”‚   â”œâ”€â”€ first_tuned_params.json # Initial tuning results
â”‚   â””â”€â”€ xgb_tuned_params.json   # XGBoost hyperparameters
â”œâ”€â”€ ğŸ“ docs/                    # Documentation
â”‚   â”œâ”€â”€ README.md               # Basic project info
â”‚   â”œâ”€â”€ README_API.md           # API documentation
â”‚   â””â”€â”€ README_DOCKER.md        # Docker deployment guide
â”œâ”€â”€ ğŸ“ dataset/                 # Data files
â”‚   â”œâ”€â”€ raw/                    # Original dataset
â”‚   â””â”€â”€ processed/              # Preprocessed data
â”œâ”€â”€ ğŸ“ models/                  # Trained model files
â”œâ”€â”€ ğŸ“ notebooks/               # Jupyter notebooks for analysis
â”œâ”€â”€ ğŸ“ mlruns/                  # MLflow experiment tracking
â”œâ”€â”€ mlflow.db                   # MLflow metadata database
â””â”€â”€ requirements.txt            # Python dependencies
```

## ğŸš€ Quick Start

### Prerequisites
- Docker Desktop (for containerized deployment)
- Python 3.10+ (for local development)

### Using Docker (Recommended)

1. **Navigate to project directory:**
   ```bash
   cd fraud_detection
   ```

2. **Start services using PowerShell:**
   ```powershell
   cd scripts
   .\manage.ps1 -Command build
   .\manage.ps1 -Command start
   ```

   **Or using Bash:**
   ```bash
   cd scripts
   chmod +x manage.sh
   ./manage.sh build
   ./manage.sh start
   ```

3. **Access services:**
   - **MLflow UI**: http://localhost:5000
   - **API Documentation**: http://localhost:8000/docs
   - **API Health**: http://localhost:8000/health

4. **Test the system:**
   ```bash
   cd scripts
   python test_docker_services.py
   ```

### Local Development

1. **Install dependencies:**
   ```bash
   pip install -r requirements.txt
   ```

2. **Start MLflow server:**
   ```bash
   mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns --host 0.0.0.0 --port 5000
   ```

3. **Start API server:**
   ```bash
   uvicorn src.api:app --host 0.0.0.0 --port 8000 --reload
   ```

## ğŸ¯ Key Features

- **ML Model Management**: MLflow for experiment tracking and model registry
- **Real-time API**: FastAPI for serving fraud detection predictions
- **Containerized Deployment**: Docker Compose for easy deployment
- **Model Training Pipeline**: Automated training with hyperparameter tuning
- **Data Preprocessing**: Complete preprocessing pipeline with encoding and scaling
- **Health Monitoring**: Health checks and service monitoring

## ğŸ“Š API Usage

### Make a Prediction
```bash
curl -X POST "http://localhost:8000/predict" \
     -H "Content-Type: application/json" \
     -d '{
       "amount": 1500.50,
       "merchant_type": "grocery",
       "device_type": "mobile"
     }'
```

### Response
```json
{
  "is_fraud": true,
  "fraud_probability": 0.76,
  "risk_level": "High",
  "transaction_details": {
    "amount": 1500.5,
    "merchant_type": "grocery",
    "device_type": "mobile"
  }
}
```

## ğŸ› ï¸ Management Commands

### PowerShell (Windows)
```powershell
# Start all services
.\scripts\manage.ps1 -Command start

# Stop all services
.\scripts\manage.ps1 -Command stop

# View logs
.\scripts\manage.ps1 -Command logs

# Check status
.\scripts\manage.ps1 -Command status
```

### Bash (Linux/Mac)
```bash
# Start all services
./scripts/manage.sh start

# Stop all services
./scripts/manage.sh stop

# View logs
./scripts/manage.sh logs

# Check status
./scripts/manage.sh status
```

## ğŸ“š Documentation

- **[API Documentation](docs/README_API.md)**: Detailed API reference
- **[Docker Deployment](docs/README_DOCKER.md)**: Complete Docker setup guide
- **[Basic Setup](docs/README.md)**: Basic project information

## ğŸ”§ Development

For development and experimentation, see the Jupyter notebooks in the `notebooks/` directory:
- `EDA.ipynb`: Exploratory Data Analysis
- `data_preparation.ipynb`: Data preparation steps
- `data_preprocessing.ipynb`: Preprocessing pipeline
- `modelling.ipynb`: Model training and evaluation
- `analisis_dan_eksperimen.ipynb`: Analysis and experiments

## ğŸ·ï¸ Model Information

The system supports multiple ML algorithms:
- Decision Tree
- XGBoost
- CatBoost
- with SMOTE for handling imbalanced data

Models are automatically tracked in MLflow with performance metrics, and the best performing model is served via the API.

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Test your changes using the provided test scripts
5. Submit a pull request

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.
