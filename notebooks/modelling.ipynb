{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c5f46af",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67259e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ramad\\Downloads\\fraud_analysis\\fraud_venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# libraries models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "# libraries feng and evaluation\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.metrics import make_scorer, accuracy_score, roc_auc_score, f1_score, recall_score, precision_score, classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Other libraries\n",
    "import optuna\n",
    "import json\n",
    "import src.util as utils\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0677b3",
   "metadata": {},
   "source": [
    "# Load Config and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecfc56a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = utils.load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c682571",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_feng(params: dict) -> pd.DataFrame:\n",
    "    # Load train set\n",
    "    X_train = utils.pickle_load(params['train_processed_set_path'][0])\n",
    "    y_train = utils.pickle_load(params['train_processed_set_path'][1])\n",
    "    \n",
    "    # Load train set transforming with log\n",
    "    X_train_log = utils.pickle_load(params['train_processed_log_set_path'][0])\n",
    "    y_train_log = utils.pickle_load(params['train_processed_log_set_path'][1])\n",
    "    \n",
    "    # Load train set SMOTE\n",
    "    X_train_SMOTE = utils.pickle_load(params['train_processed_SMOTE_set_path'][0])\n",
    "    y_train_SMOTE = utils.pickle_load(params['train_processed_SMOTE_set_path'][1])\n",
    "    \n",
    "    # Load train set wiht log and SMOTE\n",
    "    X_train_log_SMOTE = utils.pickle_load(params['train_processed_log_SMOTE_set_path'][0])\n",
    "    y_train_log_SMOTE = utils.pickle_load(params['train_processed_log_SMOTE_set_path'][1])\n",
    "\n",
    "    return X_train, y_train, X_train_log, y_train_log, X_train_SMOTE, y_train_SMOTE, X_train_log_SMOTE, y_train_log_SMOTE\n",
    "\n",
    "def load_valid(params: dict) -> pd.DataFrame:\n",
    "    # Load valid set\n",
    "    X_valid = utils.pickle_load(params['valid_processed_set_path'][0])\n",
    "    y_valid = utils.pickle_load(params['valid_processed_set_path'][1])\n",
    "    \n",
    "    # Load valid set with transforming log\n",
    "    X_valid_log = utils.pickle_load(params['valid_processed_log_set_path'][0])\n",
    "    y_valid_log = utils.pickle_load(params['valid_processed_log_set_path'][1])\n",
    "\n",
    "    return X_valid, y_valid, X_valid_log, y_valid_log\n",
    "\n",
    "def load_test(params: dict) -> pd.DataFrame:\n",
    "    # Load test set\n",
    "    X_test = utils.pickle_load(params['test_processed_set_path'][0])\n",
    "    y_test = utils.pickle_load(params['test_processed_set_path'][1])\n",
    "    \n",
    "    # Load test set with transforming log\n",
    "    X_test_log = utils.pickle_load(params['test_processed_log_set_path'][0])\n",
    "    y_test_log = utils.pickle_load(params['test_processed_log_set_path'][1])\n",
    "\n",
    "    return X_test, y_test, X_test_log, y_test_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "53d70d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data train\n",
    "X_train, y_train, X_train_log, y_train_log, X_train_SMOTE, y_train_SMOTE, X_train_log_SMOTE, y_train_log_SMOTE = load_train_feng(config)\n",
    "\n",
    "# laod data valid\n",
    "X_valid, y_valid, X_valid_log, y_valid_log = load_valid(config)\n",
    "\n",
    "# Load data test\n",
    "X_test, y_test, X_test_log, y_test_log = load_test(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "362862ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------Set Train---------------\n",
      "((700, 7), (700,)) \n",
      "\n",
      "((700, 7), (700,)) \n",
      "\n",
      "((1330, 7), (1330,)) \n",
      "\n",
      "((1330, 7), (1330,)) \n",
      "\n",
      "------------Set Valid---------------\n",
      "((150, 7), (150,)) \n",
      "\n",
      "((150, 7), (150,)) \n",
      "\n",
      "------------Set Test---------------\n",
      "((150, 7), (150,)) \n",
      "\n",
      "((150, 7), (150,)) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# checpoint/sanity check\n",
    "print('------------Set Train---------------')\n",
    "print((X_train.shape, y_train.shape), '\\n')\n",
    "print((X_train_log.shape, y_train_log.shape), '\\n')\n",
    "print((X_train_SMOTE.shape, y_train_SMOTE.shape), '\\n')\n",
    "print((X_train_log_SMOTE.shape, y_train_log_SMOTE.shape), '\\n')\n",
    "\n",
    "print('------------Set Valid---------------')\n",
    "print((X_valid.shape, y_valid.shape), '\\n')\n",
    "print((X_valid_log.shape, y_valid_log.shape), '\\n')\n",
    "\n",
    "print('------------Set Test---------------')\n",
    "print((X_test.shape, y_test.shape), '\\n')\n",
    "print((X_test_log.shape, y_test_log.shape), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d73d70",
   "metadata": {},
   "source": [
    "**For the context, the transformation log only in features (X variables). So, the naming of the log in target/label (Y) is for the sake of differentiation, the value doesn't change. Here's the proof.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc10bab4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    665\n",
       "1     35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c3c02c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    665\n",
       "1     35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f89ed329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    665\n",
       "1    665\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_log_SMOTE.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3917910a",
   "metadata": {},
   "source": [
    "# Compare Multiple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e60725ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# intialize model\n",
    "models = {\n",
    "    'gbc': GradientBoostingClassifier(random_state=42),\n",
    "    'lightgbm': lgb.LGBMClassifier(random_state=42, verbose=-1),\n",
    "    'xgb': xgb.XGBClassifier(random_state=42), \n",
    "    'rf': RandomForestClassifier(random_state=42),\n",
    "    'et': ExtraTreesClassifier(random_state=42),\n",
    "    'dt': DecisionTreeClassifier(random_state=42),\n",
    "    'knn': KNeighborsClassifier(),\n",
    "    'ada': AdaBoostClassifier(random_state=42),\n",
    "    'lr': LogisticRegression(random_state=42, solver='liblinear'), \n",
    "    'svm': SVC(random_state=42, probability=True),\n",
    "}\n",
    "\n",
    "# create function\n",
    "def get_best_models_cv(X: pd.DataFrame, y: pd.Series, models: dict, sort_by: str, n_splits: int = 5):\n",
    "    \"\"\"\n",
    "    Performs cross-validation for each model and returns a DataFrame of the results.\n",
    "\n",
    "    Args:\n",
    "        X (pd.DataFrame): The training features DataFrame.\n",
    "        y (pd.Series): The training target Series.\n",
    "        models (dict): A dictionary containing model names and model objects.\n",
    "        sort_by (str): The metric to sort the results by.\n",
    "        n_splits (int): The number of splits for StratifiedKFold.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the average metrics for each model, sorted.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    results = pd.DataFrame(columns=['Model', 'Accuracy', 'AUC', 'Recall', 'Prec.', 'F1'])\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        accuracy_scores = []\n",
    "        auc_scores = []\n",
    "        recall_scores = []\n",
    "        precision_scores = []\n",
    "        f1_scores = []\n",
    "        \n",
    "        for train_index, val_index in skf.split(X, y):\n",
    "            X_train_fold, X_val_fold = X.iloc[train_index], X.iloc[val_index]\n",
    "            y_train_fold, y_val_fold = y.iloc[train_index], y.iloc[val_index]\n",
    "            \n",
    "            model.fit(X_train_fold, y_train_fold)\n",
    "            y_pred = model.predict(X_val_fold)\n",
    "            \n",
    "            # to handle cases where the model fails predict_proba\n",
    "            if hasattr(model, 'predict_proba'):\n",
    "                try: \n",
    "                    y_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                    auc_scores.append(roc_auc_score(y_val_fold, y_proba))\n",
    "                except (ValueError, AttributeError):\n",
    "                    auc_scores.append(0.0) \n",
    "            else:\n",
    "                auc_scores.append(0.0)\n",
    "\n",
    "            accuracy_scores.append(accuracy_score(y_val_fold, y_pred))\n",
    "            recall_scores.append(recall_score(y_val_fold, y_pred))\n",
    "            precision_scores.append(precision_score(y_val_fold, y_pred))\n",
    "            f1_scores.append(f1_score(y_val_fold, y_pred))\n",
    "        \n",
    "        results.loc[len(results)] = [\n",
    "            name,\n",
    "            pd.Series(accuracy_scores).mean(),\n",
    "            pd.Series(auc_scores).mean(),\n",
    "            pd.Series(recall_scores).mean(),\n",
    "            pd.Series(precision_scores).mean(),\n",
    "            pd.Series(f1_scores).mean()\n",
    "        ]\n",
    "        \n",
    "    return results.sort_values(by=sort_by, ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180d8a0a",
   "metadata": {},
   "source": [
    "## Data No Transforming\n",
    "\n",
    "1. The data named into X_train and y_train\n",
    "2. No Transfomring means the `amount` features is left to follow the original data\n",
    "3. The unbalanced label is not handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83e57255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try experiment with data Not Transforming\n",
    "experiment_in_data_not_transforming = get_best_models_cv(\n",
    "    X_train, \n",
    "    y_train,\n",
    "    models,\n",
    "    sort_by='F1',\n",
    "    n_splits=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51414f67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.544154</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.087222</td>\n",
       "      <td>0.109341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>0.499514</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>et</td>\n",
       "      <td>0.911429</td>\n",
       "      <td>0.515273</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gbc</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>0.534227</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.587952</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.944286</td>\n",
       "      <td>0.550941</td>\n",
       "      <td>0.025000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.558011</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.515118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.481773</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.517877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy       AUC    Recall     Prec.        F1\n",
       "0        dt  0.898571  0.544154  0.150000  0.087222  0.109341\n",
       "1        rf  0.925714  0.499514  0.058333  0.075000  0.065000\n",
       "2        et  0.911429  0.515273  0.058333  0.058333  0.058333\n",
       "3       gbc  0.937143  0.534227  0.033333  0.050000  0.040000\n",
       "4  lightgbm  0.930000  0.587952  0.033333  0.050000  0.040000\n",
       "5       xgb  0.944286  0.550941  0.025000  0.100000  0.040000\n",
       "6       knn  0.950000  0.558011  0.000000  0.000000  0.000000\n",
       "7       ada  0.950000  0.515118  0.000000  0.000000  0.000000\n",
       "8        lr  0.950000  0.481773  0.000000  0.000000  0.000000\n",
       "9       svm  0.950000  0.517877  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_in_data_not_transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f4b1f7",
   "metadata": {},
   "source": [
    "## Data SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e927a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try experiment with data Not Transforming\n",
    "experiment_in_data_smote = get_best_models_cv(\n",
    "    X_train_SMOTE, \n",
    "    y_train_SMOTE,\n",
    "    models,\n",
    "    sort_by='F1',\n",
    "    n_splits=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f798624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.979003</td>\n",
       "      <td>0.930755</td>\n",
       "      <td>0.948684</td>\n",
       "      <td>0.939323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.939850</td>\n",
       "      <td>0.978799</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>0.952708</td>\n",
       "      <td>0.939047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gbc</td>\n",
       "      <td>0.938346</td>\n",
       "      <td>0.978042</td>\n",
       "      <td>0.906694</td>\n",
       "      <td>0.968451</td>\n",
       "      <td>0.936084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.931579</td>\n",
       "      <td>0.977691</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>0.937332</td>\n",
       "      <td>0.931154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>et</td>\n",
       "      <td>0.930827</td>\n",
       "      <td>0.968883</td>\n",
       "      <td>0.926278</td>\n",
       "      <td>0.935808</td>\n",
       "      <td>0.930424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.921805</td>\n",
       "      <td>0.921789</td>\n",
       "      <td>0.915717</td>\n",
       "      <td>0.927622</td>\n",
       "      <td>0.921192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.904511</td>\n",
       "      <td>0.951515</td>\n",
       "      <td>0.846698</td>\n",
       "      <td>0.960665</td>\n",
       "      <td>0.898763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.729323</td>\n",
       "      <td>0.820658</td>\n",
       "      <td>0.885776</td>\n",
       "      <td>0.674920</td>\n",
       "      <td>0.765664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.568421</td>\n",
       "      <td>0.584080</td>\n",
       "      <td>0.621099</td>\n",
       "      <td>0.562159</td>\n",
       "      <td>0.588870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.557895</td>\n",
       "      <td>0.577951</td>\n",
       "      <td>0.553076</td>\n",
       "      <td>0.560100</td>\n",
       "      <td>0.550861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy       AUC    Recall     Prec.        F1\n",
       "0  lightgbm  0.939850  0.979003  0.930755  0.948684  0.939323\n",
       "1       xgb  0.939850  0.978799  0.926278  0.952708  0.939047\n",
       "2       gbc  0.938346  0.978042  0.906694  0.968451  0.936084\n",
       "3        rf  0.931579  0.977691  0.926278  0.937332  0.931154\n",
       "4        et  0.930827  0.968883  0.926278  0.935808  0.930424\n",
       "5        dt  0.921805  0.921789  0.915717  0.927622  0.921192\n",
       "6       ada  0.904511  0.951515  0.846698  0.960665  0.898763\n",
       "7       knn  0.729323  0.820658  0.885776  0.674920  0.765664\n",
       "8        lr  0.568421  0.584080  0.621099  0.562159  0.588870\n",
       "9       svm  0.557895  0.577951  0.553076  0.560100  0.550861"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_in_data_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c8749c",
   "metadata": {},
   "source": [
    "possibility of overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8577e50e",
   "metadata": {},
   "source": [
    "## Data Transforming Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c3e819d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.529003</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.080556</td>\n",
       "      <td>0.092674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.927143</td>\n",
       "      <td>0.511200</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>et</td>\n",
       "      <td>0.911429</td>\n",
       "      <td>0.526512</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.058333</td>\n",
       "      <td>0.058333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gbc</td>\n",
       "      <td>0.937143</td>\n",
       "      <td>0.536669</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.591503</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.941429</td>\n",
       "      <td>0.552078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.445520</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.515118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.480738</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.470613</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy       AUC    Recall     Prec.        F1\n",
       "0        dt  0.900000  0.529003  0.116667  0.080556  0.092674\n",
       "1        rf  0.927143  0.511200  0.058333  0.075000  0.065000\n",
       "2        et  0.911429  0.526512  0.058333  0.058333  0.058333\n",
       "3       gbc  0.937143  0.536669  0.033333  0.050000  0.040000\n",
       "4  lightgbm  0.930000  0.591503  0.033333  0.050000  0.040000\n",
       "5       xgb  0.941429  0.552078  0.000000  0.000000  0.000000\n",
       "6       knn  0.950000  0.445520  0.000000  0.000000  0.000000\n",
       "7       ada  0.950000  0.515118  0.000000  0.000000  0.000000\n",
       "8        lr  0.950000  0.480738  0.000000  0.000000  0.000000\n",
       "9       svm  0.950000  0.470613  0.000000  0.000000  0.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_in_data_transforming = get_best_models_cv(\n",
    "    X_train_log,\n",
    "    y_train_log,\n",
    "    models,\n",
    "    sort_by='F1',\n",
    "    n_splits=10\n",
    ")\n",
    "\n",
    "experiment_in_data_transforming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e93d6c",
   "metadata": {},
   "source": [
    "## Data Trasnforming log and SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea502738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xgb</td>\n",
       "      <td>0.875188</td>\n",
       "      <td>0.957146</td>\n",
       "      <td>0.875147</td>\n",
       "      <td>0.875742</td>\n",
       "      <td>0.875101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.872932</td>\n",
       "      <td>0.957768</td>\n",
       "      <td>0.882610</td>\n",
       "      <td>0.865624</td>\n",
       "      <td>0.873659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>et</td>\n",
       "      <td>0.866165</td>\n",
       "      <td>0.903313</td>\n",
       "      <td>0.863026</td>\n",
       "      <td>0.869056</td>\n",
       "      <td>0.865390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rf</td>\n",
       "      <td>0.865414</td>\n",
       "      <td>0.944618</td>\n",
       "      <td>0.864541</td>\n",
       "      <td>0.866739</td>\n",
       "      <td>0.865070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>knn</td>\n",
       "      <td>0.855639</td>\n",
       "      <td>0.928822</td>\n",
       "      <td>0.906807</td>\n",
       "      <td>0.824379</td>\n",
       "      <td>0.862846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gbc</td>\n",
       "      <td>0.860150</td>\n",
       "      <td>0.951481</td>\n",
       "      <td>0.843510</td>\n",
       "      <td>0.872933</td>\n",
       "      <td>0.857564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dt</td>\n",
       "      <td>0.853383</td>\n",
       "      <td>0.853313</td>\n",
       "      <td>0.855518</td>\n",
       "      <td>0.852490</td>\n",
       "      <td>0.853327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ada</td>\n",
       "      <td>0.734586</td>\n",
       "      <td>0.820997</td>\n",
       "      <td>0.840728</td>\n",
       "      <td>0.693757</td>\n",
       "      <td>0.758544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.663910</td>\n",
       "      <td>0.743600</td>\n",
       "      <td>0.811963</td>\n",
       "      <td>0.626643</td>\n",
       "      <td>0.706946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.593233</td>\n",
       "      <td>0.610470</td>\n",
       "      <td>0.742899</td>\n",
       "      <td>0.571788</td>\n",
       "      <td>0.646009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy       AUC    Recall     Prec.        F1\n",
       "0       xgb  0.875188  0.957146  0.875147  0.875742  0.875101\n",
       "1  lightgbm  0.872932  0.957768  0.882610  0.865624  0.873659\n",
       "2        et  0.866165  0.903313  0.863026  0.869056  0.865390\n",
       "3        rf  0.865414  0.944618  0.864541  0.866739  0.865070\n",
       "4       knn  0.855639  0.928822  0.906807  0.824379  0.862846\n",
       "5       gbc  0.860150  0.951481  0.843510  0.872933  0.857564\n",
       "6        dt  0.853383  0.853313  0.855518  0.852490  0.853327\n",
       "7       ada  0.734586  0.820997  0.840728  0.693757  0.758544\n",
       "8       svm  0.663910  0.743600  0.811963  0.626643  0.706946\n",
       "9        lr  0.593233  0.610470  0.742899  0.571788  0.646009"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_in_data_transforming_smote = get_best_models_cv(\n",
    "    X_train_log_SMOTE,\n",
    "    y_train_log_SMOTE,\n",
    "    models,\n",
    "    sort_by='F1',\n",
    "    n_splits=10\n",
    ")\n",
    "\n",
    "experiment_in_data_transforming_smote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34fd1971",
   "metadata": {},
   "source": [
    "## Comparing The Result\n",
    "\n",
    "1. For the experiment on the data without log transformation, the accuracy metrics appear to be good. However, accuracy is not a suitable metric for imbalanced data. A more appropriate metric, such as the F1-Score, shows very low values, only around 10%.\n",
    "\n",
    "2. The same pattern is observed with the data where the amount feature was log-transformed. The accuracy is still high, but once again, the F1-score remains very poor. In fact, the F1-score after the log transformation is even worse compared to the data without the log transformation.\n",
    "\n",
    "3. **In the SMOTE data experiment, the scores across all metrics seem good. However, it is important to note that these high scores are likely due to overfitting, as the evaluation was based on sy\n",
    "nthetic data created by the SMOTE algorithm.**\n",
    "\n",
    "4. **Regarding the SMOTE data, with or without log transformation, the performance is consistently slightly better with the non-transformed data. The SMOTE-only data shows a slightly better performance compared to the SMOTE with log transformation data.**\n",
    "\n",
    "5. Therefore, further validation and evaluation will be conducted to test the model's performance on non-synthetic data (the original data that the model has not seen) to get a realistic assessment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3fa0b16",
   "metadata": {},
   "source": [
    "# Validation of The Result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4079271",
   "metadata": {},
   "source": [
    "Notes:\n",
    "* The original data has only 3 features and 1 label. These three features are very general, describing only the merchant type, device type, and the total amount spent.\n",
    "* Due to the limited data quality, the models may not be able to learn meaningful patterns effectively.\n",
    "* It is highly probable that predictions are based on chance or a lack of data context. This increases the likelihood of the models overfitting and performing poorly on the validation and test sets.\n",
    "* **The models we chose to use are based on the best performance, ranging from complex models like Gradient Boosting to a simpler model like Decision Tree.**\n",
    "* **Tree-based models are favored over linear or distance-based models due to their better empirical performance. This, however, does not change our belief that there is still a significant potential for overfitting because of the data's limited quality.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253c9a9",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a49a7a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model (initliaze)\n",
    "gbc_model = GradientBoostingClassifier(random_state=42)\n",
    "xgb_model = xgb.XGBClassifier(random_state=42)\n",
    "lgb_model = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "dt_model = DecisionTreeClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6dd4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluate model\n",
    "def get_validation_metrics_df(model_name, y_true, y_pred, y_proba):\n",
    "    \"\"\"\n",
    "     Calculates the evaluation metrics and returns them as a DataFrame.\n",
    "    \"\"\"\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    \n",
    "    metrics = {\n",
    "        'Model': [model_name],\n",
    "        'Accuracy': [accuracy],\n",
    "        'Recall': [recall],\n",
    "        'Prec.': [precision],\n",
    "        'F1': [f1],\n",
    "        'AUC': [auc]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c25d5d1",
   "metadata": {},
   "source": [
    "## Validation in Data non SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c17f6",
   "metadata": {},
   "source": [
    "Dalam data yang tanpa SMOTE baik, untuk data dengan transforming log (amount) atau tidak, model dt (decision tree) adalah yang terbaik memberikan hasil, dalam konteks ini f1 score paling tinggi, meskipun secara nilai masih sanagat rendah. Maka dari itu, perlu dicek lebih hasil model dalam data validasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "719ace2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model_cv_report(model, X_train, y_train, n_splits=5):\n",
    "    \"\"\"\n",
    "    Performs cross-validation on a single model and returns a DataFrame\n",
    "    containing per-fold metrics and their average.\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    results = pd.DataFrame(columns=['Fold', 'Accuracy', 'AUC', 'Recall', 'Prec.', 'F1'])\n",
    "    \n",
    "    accuracy_scores = []\n",
    "    auc_scores = []\n",
    "    recall_scores = []\n",
    "    precision_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # Fit the model on each fold\n",
    "        model.fit(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Predict on the validation fold\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        # Handle models without predict_proba if necessary, though it's assumed for AUC\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            try: \n",
    "                y_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                auc = roc_auc_score(y_val_fold, y_proba)\n",
    "            except (ValueError, AttributeError):\n",
    "                auc = 0.0\n",
    "        else:\n",
    "            auc = 0.0\n",
    "        \n",
    "        # Calculate metrics\n",
    "        acc = accuracy_score(y_val_fold, y_pred)\n",
    "        rec = recall_score(y_val_fold, y_pred, zero_division=0)\n",
    "        prec = precision_score(y_val_fold, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
    "\n",
    "        # Store metrics for calculating the average\n",
    "        accuracy_scores.append(acc)\n",
    "        auc_scores.append(auc)\n",
    "        recall_scores.append(rec)\n",
    "        precision_scores.append(prec)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        # Store per-fold results\n",
    "        results.loc[len(results)] = [f\"Fold {fold}\", acc, auc, rec, prec, f1]\n",
    "\n",
    "    # Add the mean row\n",
    "    results.loc[len(results)] = ['Mean', pd.Series(accuracy_scores).mean(), pd.Series(auc_scores).mean(), pd.Series(recall_scores).mean(), pd.Series(precision_scores).mean(), pd.Series(f1_scores).mean()]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b4bb87",
   "metadata": {},
   "source": [
    "### model decision tree (dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22f391c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fold 0</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fold 1</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.644279</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fold 2</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.810945</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fold 3</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fold 4</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.492537</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fold 5</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fold 6</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fold 7</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fold 8</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.439394</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fold 9</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.898571</td>\n",
       "      <td>0.544154</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.087222</td>\n",
       "      <td>0.109341</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fold  Accuracy       AUC    Recall     Prec.        F1\n",
       "0   Fold 0  0.828571  0.432836  0.000000  0.000000  0.000000\n",
       "1   Fold 1  0.928571  0.644279  0.333333  0.250000  0.285714\n",
       "2   Fold 2  0.942857  0.810945  0.666667  0.400000  0.500000\n",
       "3   Fold 3  0.914286  0.477612  0.000000  0.000000  0.000000\n",
       "4   Fold 4  0.942857  0.492537  0.000000  0.000000  0.000000\n",
       "5   Fold 5  0.914286  0.484848  0.000000  0.000000  0.000000\n",
       "6   Fold 6  0.871429  0.696970  0.500000  0.222222  0.307692\n",
       "7   Fold 7  0.928571  0.492424  0.000000  0.000000  0.000000\n",
       "8   Fold 8  0.828571  0.439394  0.000000  0.000000  0.000000\n",
       "9   Fold 9  0.885714  0.469697  0.000000  0.000000  0.000000\n",
       "10    Mean  0.898571  0.544154  0.150000  0.087222  0.109341"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to fit in multiple fold (no log transform)\n",
    "single_model_cv_report(dt_model, X_train, y_train, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "714e3275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree (without Tuned)</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Accuracy  Recall  Prec.   F1       AUC\n",
       "0  Decision Tree (without Tuned)      0.92     0.0    0.0  0.0  0.485915"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model_dt = dt_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_dt = fit_model_dt.predict(X_valid)\n",
    "y_proba_dt = fit_model_dt.predict_proba(X_valid)[:, 1] \n",
    "\n",
    "dt_metrics_eval = get_validation_metrics_df(\n",
    "    'Decision Tree (without Tuned)', \n",
    "    y_valid,   \n",
    "    y_pred_dt,      \n",
    "    y_proba_dt       \n",
    ")\n",
    "\n",
    "dt_metrics_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5fc0c6",
   "metadata": {},
   "source": [
    "pada beberapa fold f1 score sempat mencapai 0.50 dengan recall dan precision cukup tinggi. Namun balik lagi ini, masih dalam data training sangat mungkin overfitting. Terbukti saat divalidasi, model akurasi cukup baik, namun AUC masih rendah bahkan, Recall, Precision dan F1 menghasilkan 0. Performa model buruk, namun hasil ini tetap saja membuka peluang untuk coba di tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e1635ea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fold 0</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fold 1</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.651741</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fold 2</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.644279</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fold 3</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fold 4</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.485075</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fold 5</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.484848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fold 6</td>\n",
       "      <td>0.871429</td>\n",
       "      <td>0.696970</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fold 7</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.492424</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fold 8</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fold 9</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.469697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.529003</td>\n",
       "      <td>0.116667</td>\n",
       "      <td>0.080556</td>\n",
       "      <td>0.092674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fold  Accuracy       AUC    Recall     Prec.        F1\n",
       "0   Fold 0  0.828571  0.432836  0.000000  0.000000  0.000000\n",
       "1   Fold 1  0.942857  0.651741  0.333333  0.333333  0.333333\n",
       "2   Fold 2  0.928571  0.644279  0.333333  0.250000  0.285714\n",
       "3   Fold 3  0.914286  0.477612  0.000000  0.000000  0.000000\n",
       "4   Fold 4  0.928571  0.485075  0.000000  0.000000  0.000000\n",
       "5   Fold 5  0.914286  0.484848  0.000000  0.000000  0.000000\n",
       "6   Fold 6  0.871429  0.696970  0.500000  0.222222  0.307692\n",
       "7   Fold 7  0.928571  0.492424  0.000000  0.000000  0.000000\n",
       "8   Fold 8  0.857143  0.454545  0.000000  0.000000  0.000000\n",
       "9   Fold 9  0.885714  0.469697  0.000000  0.000000  0.000000\n",
       "10    Mean  0.900000  0.529003  0.116667  0.080556  0.092674"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to fit in multiple fold (with log transform data)\n",
    "single_model_cv_report(dt_model, X_train_log, y_train_log, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba45edce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Decision Tree (without Tuned) in transf. log</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.485915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model  Accuracy  Recall  Prec.   F1  \\\n",
       "0  Decision Tree (without Tuned) in transf. log      0.92     0.0    0.0  0.0   \n",
       "\n",
       "        AUC  \n",
       "0  0.485915  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# metrics in data validation\n",
    "fit_model_dt_data_log = dt_model.fit(X_train_log, y_train_log)\n",
    "\n",
    "y_pred_dt_data_log = fit_model_dt_data_log.predict(X_valid_log)\n",
    "y_proba_dt_data_log = fit_model_dt_data_log.predict_proba(X_valid_log)[:, 1] \n",
    "\n",
    "dt_metrics_eval_data_log = get_validation_metrics_df(\n",
    "    'Decision Tree (without Tuned) in transf. log', \n",
    "    y_valid_log,   \n",
    "    y_pred_dt_data_log,      \n",
    "    y_proba_dt_data_log       \n",
    ")\n",
    "\n",
    "dt_metrics_eval_data_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92595aa5",
   "metadata": {},
   "source": [
    "Secara akurasi, performa model tidak jauh berbeda antara data tanpa transformasi log dan data dengan transformasi log (~92%). Namun, terbukti kembali bahwa model mengalami overfitting yang parah. Saat divalidasi, model gagal mendeteksi satu pun kasus fraud, ditunjukkan oleh Recall, Precision, dan F1-Score yang semuanya menghasilkan 0.0, bahkan AUC berada di bawah nilai rata-rata.\n",
    "\n",
    "Saat cross-validation model dt pada data tanpa transformasi log menunjukkan nilai rata-rata F1-Score yang sedikit lebih baik (0.109) dibandingkan dengan data transformasi log (0.092). \n",
    "\n",
    "Oleh karena itu, data tanpa transformasi log akan menjadi kandidat yang lebih menjanjikan untuk dicoba di-tuning lebih dengan model sederhana menggunakan model Decision Tree (dt)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd83f42",
   "metadata": {},
   "source": [
    "## Validation in SMOTE Data\n",
    "\n",
    "Secara hasil, model berbasis tree yang lebih kompleks seperti XGBoost dan LightGBM menghasilkan performa metrik tertinggi, terutama pada F1-Score, di eksperimen dengan data SMOTE.\n",
    "\n",
    "Maka dari itu, untuk mendapatkan hasil yang tidak overfitting, kita akan memvalidasi model-model tersebut pada set validasi. Namun, sebelum itu, kita akan menjalankan/membuat ulang fungsi cross-validation dengan metodologi yang benar, di mana SMOTE akan diterapkan di dalam fungsi cross-validation pada setiap fold untuk menghindari data leakage seperti yang terjadi pada data SMOTE di fungsi `get_best_models_cv`. \n",
    "\n",
    "Adapun, data yang coba divalidasi hasilnya hanya pada data SMOTE karena meghasilkan performa lebih baik dibandingkan SMOTE dan log transform di fitur amount. Meskipun, hasilnya metrik dari data SMOTE menggunakan `get_best_model_cv` memiliki potensi leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8226642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def single_model_cv_report_smote(model, X_train, y_train, n_splits=5):\n",
    "    \"\"\"\n",
    "    Performs cross-validation with SMOTE applied on each fold's training data.\n",
    "    \"\"\"\n",
    "    smote = SMOTE(random_state=42)\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    results = pd.DataFrame(columns=['Fold', 'Accuracy', 'AUC', 'Recall', 'Prec.', 'F1'])\n",
    "    \n",
    "    all_metrics = {metric: [] for metric in ['Accuracy', 'AUC', 'Recall', 'Prec.', 'F1']}\n",
    "\n",
    "    for fold, (train_index, val_index) in enumerate(skf.split(X_train, y_train)):\n",
    "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[val_index]\n",
    "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[val_index]\n",
    "        \n",
    "        # --- Solusi: Terapkan SMOTE di sini ---\n",
    "        X_train_smoted, y_train_smoted = smote.fit_resample(X_train_fold, y_train_fold)\n",
    "        \n",
    "        # Fit the model on SMOTE-d data\n",
    "        model.fit(X_train_smoted, y_train_smoted)\n",
    "        \n",
    "        # Predict on the original validation fold\n",
    "        y_pred = model.predict(X_val_fold)\n",
    "        \n",
    "        # Calculate metrics (logic remains the same)\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            try:\n",
    "                y_proba = model.predict_proba(X_val_fold)[:, 1]\n",
    "                auc = roc_auc_score(y_val_fold, y_proba)\n",
    "            except (ValueError, AttributeError):\n",
    "                auc = np.nan\n",
    "        else:\n",
    "            auc = np.nan\n",
    "        \n",
    "        acc = accuracy_score(y_val_fold, y_pred)\n",
    "        rec = recall_score(y_val_fold, y_pred, zero_division=0)\n",
    "        prec = precision_score(y_val_fold, y_pred, zero_division=0)\n",
    "        f1 = f1_score(y_val_fold, y_pred, zero_division=0)\n",
    "        \n",
    "        # Store all per-fold metrics\n",
    "        all_metrics['Accuracy'].append(acc)\n",
    "        all_metrics['AUC'].append(auc)\n",
    "        all_metrics['Recall'].append(rec)\n",
    "        all_metrics['Prec.'].append(prec)\n",
    "        all_metrics['F1'].append(f1)\n",
    "        \n",
    "        # Store per-fold results in DataFrame\n",
    "        results.loc[len(results)] = [f\"Fold {fold}\", acc, auc, rec, prec, f1]\n",
    "\n",
    "    # Add the mean row using the stored metrics\n",
    "    results.loc[len(results)] = ['Mean', \n",
    "                                 pd.Series(all_metrics['Accuracy']).mean(),\n",
    "                                 pd.Series(all_metrics['AUC']).mean(skipna=True),\n",
    "                                 pd.Series(all_metrics['Recall']).mean(),\n",
    "                                 pd.Series(all_metrics['Prec.']).mean(),\n",
    "                                 pd.Series(all_metrics['F1']).mean()]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f2a209",
   "metadata": {},
   "source": [
    "### model xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e30479e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fold 0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fold 1</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.646766</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fold 2</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.681592</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fold 3</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.756219</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fold 4</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.497512</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fold 5</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.560606</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fold 6</td>\n",
       "      <td>0.885714</td>\n",
       "      <td>0.503788</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fold 7</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.268939</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fold 8</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.609848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fold 9</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.482955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.556046</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.078333</td>\n",
       "      <td>0.086905</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fold  Accuracy       AUC    Recall     Prec.        F1\n",
       "0   Fold 0  0.942857  0.552239  0.000000  0.000000  0.000000\n",
       "1   Fold 1  0.928571  0.646766  0.333333  0.250000  0.285714\n",
       "2   Fold 2  0.942857  0.681592  0.333333  0.333333  0.333333\n",
       "3   Fold 3  0.914286  0.756219  0.333333  0.200000  0.250000\n",
       "4   Fold 4  0.928571  0.497512  0.000000  0.000000  0.000000\n",
       "5   Fold 5  0.928571  0.560606  0.000000  0.000000  0.000000\n",
       "6   Fold 6  0.885714  0.503788  0.000000  0.000000  0.000000\n",
       "7   Fold 7  0.928571  0.268939  0.000000  0.000000  0.000000\n",
       "8   Fold 8  0.900000  0.609848  0.000000  0.000000  0.000000\n",
       "9   Fold 9  0.842857  0.482955  0.000000  0.000000  0.000000\n",
       "10    Mean  0.914286  0.556046  0.100000  0.078333  0.086905"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to fit in mutlitple fold (with data SMOTE not transforming log)\n",
    "single_model_cv_report_smote(xgb_model, X_train, y_train, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8739a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Not Tuned</td>\n",
       "      <td>0.913333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.383803</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Accuracy  Recall  Prec.   F1       AUC\n",
       "0  XGBoost Not Tuned  0.913333     0.0    0.0  0.0  0.383803"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# validate the result on data that the model has never seen before\n",
    "# predict on set validation (X_valid)\n",
    "fit_model_xgb = xgb_model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "y_pred_xgb = fit_model_xgb.predict(X_valid)\n",
    "y_proba_xgb = fit_model_xgb.predict_proba(X_valid)[:, 1] \n",
    "\n",
    "xgb_metrics_eval = get_validation_metrics_df(\n",
    "    'XGBoost Not Tuned', \n",
    "    y_valid,   \n",
    "    y_pred_xgb,      \n",
    "    y_proba_xgb       \n",
    ")\n",
    "\n",
    "xgb_metrics_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f10c21",
   "metadata": {},
   "source": [
    "Dengan membuang potensi leakage pada cross validation di fungsi `get_best_models_cv` untuk data SMOTE, model xgb dengan bantuan SMOTE sebenarnya tidak memberikan pengaruh begitu besar pada peningkatan performa. Asumsi/hipotesis awal soal data yang jelek semakin terbukti karena SMOTE tidak mengangkat performa model. Bahkan cenderung, performa lebih buruk karena dibanding model simpel untuk data tanpa SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f765b0fb",
   "metadata": {},
   "source": [
    "**The model is still overfitting** because it is only able to achieve a high score on this specific metric and is only good on data training. We try to tune before conclude the reason that **the main problem remains the data, not the algorithm. Garbage in garbage out**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24b8950",
   "metadata": {},
   "source": [
    "### Model lgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49697b64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fold 0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.487562</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fold 1</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fold 2</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.746269</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Fold 3</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.656716</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fold 4</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.432836</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Fold 5</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fold 6</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fold 7</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.234848</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Fold 8</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.594697</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fold 9</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.494318</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mean</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>0.524409</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fold  Accuracy       AUC    Recall  Prec.     F1\n",
       "0   Fold 0  0.942857  0.487562  0.000000   0.00  0.000\n",
       "1   Fold 1  0.914286  0.691542  0.333333   0.20  0.250\n",
       "2   Fold 2  0.914286  0.746269  0.000000   0.00  0.000\n",
       "3   Fold 3  0.900000  0.656716  0.000000   0.00  0.000\n",
       "4   Fold 4  0.928571  0.432836  0.000000   0.00  0.000\n",
       "5   Fold 5  0.928571  0.541667  0.000000   0.00  0.000\n",
       "6   Fold 6  0.900000  0.363636  0.000000   0.00  0.000\n",
       "7   Fold 7  0.928571  0.234848  0.000000   0.00  0.000\n",
       "8   Fold 8  0.914286  0.594697  0.000000   0.00  0.000\n",
       "9   Fold 9  0.828571  0.494318  0.000000   0.00  0.000\n",
       "10    Mean  0.910000  0.524409  0.033333   0.02  0.025"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try to fit in mutlitple fold (data SMOTE)\n",
    "single_model_cv_report_smote(lgb_model, X_train, y_train, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c94af5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Prec.</th>\n",
       "      <th>F1</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LightGBM Not Tuned</td>\n",
       "      <td>0.886667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.360035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Accuracy  Recall  Prec.   F1       AUC\n",
       "0  LightGBM Not Tuned  0.886667     0.0    0.0  0.0  0.360035"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_model_lgb = lgb_model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "y_pred_lgb = fit_model_lgb.predict(X_valid)\n",
    "y_proba_lgb = fit_model_lgb.predict_proba(X_valid)[:, 1] \n",
    "\n",
    "lgb_metrics_eval = get_validation_metrics_df(\n",
    "    'LightGBM Not Tuned', \n",
    "    y_valid,   \n",
    "    y_pred_lgb,      \n",
    "    y_proba_lgb       \n",
    ")\n",
    "\n",
    "lgb_metrics_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31b729b",
   "metadata": {},
   "source": [
    "Hasil ini juga menunjukkan bahwa SMOTE tidak terlalu ngaruh untuk urusan meningkatkan performa model. Model masih kesusahan dalam memrpediksi data yang benar 1 ataupun data yang benar 0. F1 score juga masih sangat kecil.\n",
    "\n",
    "Bahkan saat di evaluasi dengan set validation nilainya tidak lebih baik dibandingkan model XGBoost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475c9ee7",
   "metadata": {},
   "source": [
    "## Recap on Validation The Result\n",
    "\n",
    "1. Berdasarkan hasil, ada dua model yang akan coba dituning. Pertama, model simpel dengan `decision tree` untuk data Non-SMOTE. Kedua, model lebih kompleks dengan `XGBoost`.\n",
    "2. Penentuan ini berdasarkan hasil performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac1d6e42",
   "metadata": {},
   "source": [
    "# Tuning\n",
    "\n",
    "The model that will be tuned is the best-performing one, which are `decision tree` and `XGBoost`.\n",
    "\n",
    "We'll using optuna to tune the model, ref:\n",
    "1. https://xgboosting.com/xgboost-hyperparameter-optimization-with-optuna/\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb889302",
   "metadata": {},
   "source": [
    "## Data Non-SMOTE (Original) with Decision Tree (dt) Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "674ac146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-03 23:01:13,870] A new study created in memory with name: no-name-90bf4647-70d5-4fc8-bd97-9a375d4ab7d1\n",
      "[I 2025-08-03 23:01:13,927] Trial 0 finished with values: [0.0, 0.9357142857142857] and parameters: {'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 4, 'min_samples_leaf': 3, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:13,972] Trial 1 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 8, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,012] Trial 2 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 17, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,054] Trial 3 finished with values: [0.08646250042131048, 0.5057142857142858] and parameters: {'criterion': 'gini', 'max_depth': 7, 'min_samples_split': 17, 'min_samples_leaf': 11, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,092] Trial 4 finished with values: [0.0, 0.9457142857142857] and parameters: {'criterion': 'gini', 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 4, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,136] Trial 5 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 13, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,175] Trial 6 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 18, 'min_samples_leaf': 12, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,218] Trial 7 finished with values: [0.10105152836371023, 0.6285714285714286] and parameters: {'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 20, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,260] Trial 8 finished with values: [0.07356326908657876, 0.7328571428571428] and parameters: {'criterion': 'gini', 'max_depth': 14, 'min_samples_split': 7, 'min_samples_leaf': 2, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,300] Trial 9 finished with values: [0.11064680000850213, 0.6514285714285715] and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 12, 'min_samples_leaf': 14, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,335] Trial 10 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 19, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,376] Trial 11 finished with values: [0.10528682248135728, 0.6542857142857142] and parameters: {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 2, 'min_samples_leaf': 20, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,416] Trial 12 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 31, 'min_samples_split': 9, 'min_samples_leaf': 16, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,457] Trial 13 finished with values: [0.10348221976128953, 0.7442857142857143] and parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 17, 'min_samples_leaf': 7, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,499] Trial 14 finished with values: [0.10528682248135728, 0.6542857142857142] and parameters: {'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 15, 'min_samples_leaf': 20, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,541] Trial 15 finished with values: [0.10601092896174862, 0.7342857142857143] and parameters: {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 8, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,580] Trial 16 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 15, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,625] Trial 17 finished with values: [0.10845245200185419, 0.67] and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 10, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,660] Trial 18 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 13, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,708] Trial 19 finished with values: [0.0, 0.9342857142857144] and parameters: {'criterion': 'entropy', 'max_depth': 15, 'min_samples_split': 19, 'min_samples_leaf': 1, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,753] Trial 20 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 14, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,797] Trial 21 finished with values: [0.10627749415877259, 0.20714285714285716] and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 2, 'min_samples_leaf': 3, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,844] Trial 22 finished with values: [0.11021203148425789, 0.23857142857142857] and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 19, 'min_samples_leaf': 2, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,892] Trial 23 finished with values: [0.10388162478448934, 0.21285714285714286] and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 20, 'min_samples_leaf': 16, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:14,933] Trial 24 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 16, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:14,974] Trial 25 finished with values: [0.10201835525364937, 0.37] and parameters: {'criterion': 'entropy', 'max_depth': 4, 'min_samples_split': 14, 'min_samples_leaf': 10, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,017] Trial 26 finished with values: [0.13813095348635462, 0.66] and parameters: {'criterion': 'entropy', 'max_depth': 31, 'min_samples_split': 14, 'min_samples_leaf': 12, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,064] Trial 27 finished with values: [0.05615763546798029, 0.8200000000000001] and parameters: {'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 15, 'min_samples_leaf': 1, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,128] Trial 28 finished with values: [0.09324750277469478, 0.667142857142857] and parameters: {'criterion': 'gini', 'max_depth': 15, 'min_samples_split': 11, 'min_samples_leaf': 12, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,186] Trial 29 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 15, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,225] Trial 30 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 18, 'min_samples_leaf': 13, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,267] Trial 31 finished with values: [0.10448968986284528, 0.52] and parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 2, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,303] Trial 32 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 19, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,344] Trial 33 finished with values: [0.13673673673673675, 0.8257142857142856] and parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 4, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,382] Trial 34 finished with values: [0.11095347628958582, 0.24428571428571427] and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 2, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,420] Trial 35 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 1, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,462] Trial 36 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 18, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,506] Trial 37 finished with values: [0.08161140015462086, 0.6785714285714286] and parameters: {'criterion': 'gini', 'max_depth': 25, 'min_samples_split': 5, 'min_samples_leaf': 9, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,553] Trial 38 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 18, 'min_samples_leaf': 20, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,595] Trial 39 finished with values: [0.10157127532024987, 0.6428571428571429] and parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 13, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,634] Trial 40 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 18, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,672] Trial 41 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 18, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,719] Trial 42 finished with values: [0.10286818800238944, 0.6228571428571429] and parameters: {'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 16, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,759] Trial 43 finished with values: [0.0, 0.9485714285714286] and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 1, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,802] Trial 44 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 11, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,848] Trial 45 finished with values: [0.0990171507199371, 0.5914285714285714] and parameters: {'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 10, 'min_samples_leaf': 19, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,888] Trial 46 finished with values: [0.0, 0.9442857142857143] and parameters: {'criterion': 'gini', 'max_depth': 29, 'min_samples_split': 20, 'min_samples_leaf': 3, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:15,934] Trial 47 finished with values: [0.12328168146691303, 0.6328571428571428] and parameters: {'criterion': 'entropy', 'max_depth': 27, 'min_samples_split': 2, 'min_samples_leaf': 15, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:15,973] Trial 48 finished with values: [0.08808734266181076, 0.5214285714285715] and parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 16, 'min_samples_leaf': 12, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:16,010] Trial 49 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,077] Trial 50 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 15, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,114] Trial 51 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 16, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,158] Trial 52 finished with values: [0.17095238095238094, 0.8357142857142857] and parameters: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 4, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:16,198] Trial 53 finished with values: [0.10627749415877259, 0.20714285714285716] and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 1, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:16,238] Trial 54 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 17, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,281] Trial 55 finished with values: [0.0, 0.9428571428571428] and parameters: {'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 2, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,322] Trial 56 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 15, 'min_samples_leaf': 14, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,361] Trial 57 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 10, 'min_samples_leaf': 11, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,402] Trial 58 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 19, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,445] Trial 59 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 15, 'min_samples_leaf': 8, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,488] Trial 60 finished with values: [0.09647812971342382, 0.47714285714285715] and parameters: {'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 18, 'min_samples_leaf': 10, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:16,527] Trial 61 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 9, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,573] Trial 62 finished with values: [0.10528682248135728, 0.6542857142857142] and parameters: {'criterion': 'entropy', 'max_depth': 22, 'min_samples_split': 15, 'min_samples_leaf': 20, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:16,617] Trial 63 finished with values: [0.1137171974052779, 0.6071428571428571] and parameters: {'criterion': 'entropy', 'max_depth': 32, 'min_samples_split': 19, 'min_samples_leaf': 19, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:16,657] Trial 64 finished with values: [0.0977558582868225, 0.547142857142857] and parameters: {'criterion': 'gini', 'max_depth': 6, 'min_samples_split': 4, 'min_samples_leaf': 8, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:16,698] Trial 65 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 19, 'min_samples_leaf': 16, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,740] Trial 66 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 6, 'min_samples_leaf': 18, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,780] Trial 67 finished with values: [0.10719280719280719, 0.8300000000000001] and parameters: {'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 9, 'min_samples_leaf': 2, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:16,818] Trial 68 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 15, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,861] Trial 69 finished with values: [0.0, 0.9457142857142857] and parameters: {'criterion': 'entropy', 'max_depth': 30, 'min_samples_split': 17, 'min_samples_leaf': 7, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,901] Trial 70 finished with values: [0.10528682248135728, 0.6542857142857142] and parameters: {'criterion': 'entropy', 'max_depth': 17, 'min_samples_split': 15, 'min_samples_leaf': 20, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:16,941] Trial 71 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 10, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:16,979] Trial 72 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 15, 'min_samples_leaf': 19, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,020] Trial 73 finished with values: [0.10864088925259138, 0.6242857142857143] and parameters: {'criterion': 'gini', 'max_depth': 23, 'min_samples_split': 4, 'min_samples_leaf': 15, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,063] Trial 74 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 19, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,105] Trial 75 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 15, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,147] Trial 76 finished with values: [0.1137171974052779, 0.6071428571428571] and parameters: {'criterion': 'entropy', 'max_depth': 21, 'min_samples_split': 12, 'min_samples_leaf': 19, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,189] Trial 77 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 11, 'min_samples_leaf': 15, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,231] Trial 78 finished with values: [0.10582010582010581, 0.8485714285714285] and parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 3, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,276] Trial 79 finished with values: [0.12932539682539682, 0.7485714285714286] and parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 17, 'min_samples_leaf': 7, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,319] Trial 80 finished with values: [0.11339215678722778, 0.6285714285714286] and parameters: {'criterion': 'entropy', 'max_depth': 14, 'min_samples_split': 2, 'min_samples_leaf': 16, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,364] Trial 81 finished with values: [0.10105152836371023, 0.6285714285714286] and parameters: {'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 6, 'min_samples_leaf': 20, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,404] Trial 82 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 17, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,443] Trial 83 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 13, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,486] Trial 84 finished with values: [0.12328168146691303, 0.6328571428571428] and parameters: {'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 9, 'min_samples_leaf': 15, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,525] Trial 85 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 20, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,566] Trial 86 finished with values: [0.097073432811613, 0.5900000000000001] and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 18, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,608] Trial 87 finished with values: [0.12097691535630646, 0.7214285714285715] and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 12, 'min_samples_leaf': 8, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,647] Trial 88 finished with values: [0.10039742825351913, 0.26142857142857145] and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 2, 'min_samples_leaf': 17, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,688] Trial 89 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 16, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,727] Trial 90 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 18, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,774] Trial 91 finished with values: [0.07990118891120004, 0.5871428571428571] and parameters: {'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 4, 'min_samples_leaf': 11, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,823] Trial 92 finished with values: [0.07700788827781682, 0.6385714285714286] and parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 20, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,865] Trial 93 finished with values: [0.05517241379310345, 0.8185714285714287] and parameters: {'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 15, 'min_samples_leaf': 1, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,910] Trial 94 finished with values: [0.08960794844253492, 0.6957142857142857] and parameters: {'criterion': 'entropy', 'max_depth': 31, 'min_samples_split': 5, 'min_samples_leaf': 9, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:17,953] Trial 95 finished with values: [0.0, 0.95] and parameters: {'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 20, 'min_samples_leaf': 20, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:17,992] Trial 96 finished with values: [0.0, 0.9385714285714286] and parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 9, 'min_samples_leaf': 2, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:18,030] Trial 97 finished with values: [0.11021203148425789, 0.23857142857142857] and parameters: {'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 9, 'min_samples_leaf': 6, 'class_weight': 'balanced'}.\n",
      "[I 2025-08-03 23:01:18,070] Trial 98 finished with values: [0.0, 0.95] and parameters: {'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 14, 'class_weight': None}.\n",
      "[I 2025-08-03 23:01:18,108] Trial 99 finished with values: [0.10627749415877259, 0.20714285714285716] and parameters: {'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 7, 'min_samples_leaf': 2, 'class_weight': 'balanced'}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Multi-objective Tuning in Decision Tree ---\n",
      "Pareto Optimal Solutions in Decision Tree:\n",
      "Trial 1: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 2, 'min_samples_leaf': 8, 'class_weight': None}\n",
      "Trial 2: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 17, 'class_weight': None}\n",
      "Trial 5: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 23, 'min_samples_split': 5, 'min_samples_leaf': 13, 'class_weight': None}\n",
      "Trial 6: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 18, 'min_samples_leaf': 12, 'class_weight': None}\n",
      "Trial 10: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 4, 'min_samples_leaf': 19, 'class_weight': None}\n",
      "Trial 12: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 31, 'min_samples_split': 9, 'min_samples_leaf': 16, 'class_weight': None}\n",
      "Trial 16: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 2, 'min_samples_leaf': 15, 'class_weight': None}\n",
      "Trial 18: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 13, 'class_weight': None}\n",
      "Trial 20: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 5, 'min_samples_split': 9, 'min_samples_leaf': 14, 'class_weight': None}\n",
      "Trial 24: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 4, 'min_samples_leaf': 16, 'class_weight': None}\n",
      "Trial 29: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 16, 'min_samples_split': 13, 'min_samples_leaf': 15, 'class_weight': None}\n",
      "Trial 30: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 18, 'min_samples_leaf': 13, 'class_weight': None}\n",
      "Trial 32: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 15, 'min_samples_leaf': 19, 'class_weight': None}\n",
      "Trial 35: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 10, 'min_samples_leaf': 1, 'class_weight': None}\n",
      "Trial 36: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 5, 'min_samples_leaf': 18, 'class_weight': None}\n",
      "Trial 38: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 26, 'min_samples_split': 18, 'min_samples_leaf': 20, 'class_weight': None}\n",
      "Trial 40: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 4, 'min_samples_leaf': 18, 'class_weight': None}\n",
      "Trial 41: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 7, 'min_samples_leaf': 18, 'class_weight': None}\n",
      "Trial 44: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 10, 'min_samples_leaf': 11, 'class_weight': None}\n",
      "Trial 49: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 3, 'min_samples_leaf': 8, 'class_weight': None}\n",
      "Trial 50: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 16, 'min_samples_split': 17, 'min_samples_leaf': 15, 'class_weight': None}\n",
      "Trial 51: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 16, 'class_weight': None}\n",
      "Trial 52: F1=0.1710, Accuracy=0.8357, Params={'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 4, 'class_weight': 'balanced'}\n",
      "Trial 54: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 27, 'min_samples_split': 3, 'min_samples_leaf': 17, 'class_weight': None}\n",
      "Trial 56: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 18, 'min_samples_split': 15, 'min_samples_leaf': 14, 'class_weight': None}\n",
      "Trial 57: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 32, 'min_samples_split': 10, 'min_samples_leaf': 11, 'class_weight': None}\n",
      "Trial 58: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 10, 'min_samples_leaf': 19, 'class_weight': None}\n",
      "Trial 59: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 12, 'min_samples_split': 15, 'min_samples_leaf': 8, 'class_weight': None}\n",
      "Trial 61: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 2, 'min_samples_split': 18, 'min_samples_leaf': 9, 'class_weight': None}\n",
      "Trial 65: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 2, 'min_samples_split': 19, 'min_samples_leaf': 16, 'class_weight': None}\n",
      "Trial 66: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 24, 'min_samples_split': 6, 'min_samples_leaf': 18, 'class_weight': None}\n",
      "Trial 68: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 4, 'min_samples_split': 19, 'min_samples_leaf': 15, 'class_weight': None}\n",
      "Trial 71: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 19, 'min_samples_split': 6, 'min_samples_leaf': 10, 'class_weight': None}\n",
      "Trial 72: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 15, 'min_samples_leaf': 19, 'class_weight': None}\n",
      "Trial 74: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 9, 'min_samples_split': 9, 'min_samples_leaf': 19, 'class_weight': None}\n",
      "Trial 75: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 10, 'min_samples_split': 15, 'min_samples_leaf': 15, 'class_weight': None}\n",
      "Trial 77: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 24, 'min_samples_split': 11, 'min_samples_leaf': 15, 'class_weight': None}\n",
      "Trial 78: F1=0.1058, Accuracy=0.8486, Params={'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 3, 'min_samples_leaf': 3, 'class_weight': 'balanced'}\n",
      "Trial 82: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 3, 'min_samples_split': 14, 'min_samples_leaf': 17, 'class_weight': None}\n",
      "Trial 83: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 9, 'min_samples_split': 11, 'min_samples_leaf': 13, 'class_weight': None}\n",
      "Trial 85: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 3, 'min_samples_leaf': 20, 'class_weight': None}\n",
      "Trial 89: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 13, 'min_samples_split': 2, 'min_samples_leaf': 16, 'class_weight': None}\n",
      "Trial 90: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 3, 'min_samples_split': 7, 'min_samples_leaf': 18, 'class_weight': None}\n",
      "Trial 95: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'entropy', 'max_depth': 11, 'min_samples_split': 20, 'min_samples_leaf': 20, 'class_weight': None}\n",
      "Trial 98: F1=0.0000, Accuracy=0.9500, Params={'criterion': 'gini', 'max_depth': 26, 'min_samples_split': 2, 'min_samples_leaf': 14, 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "def objective_dt_tuned(trial):\n",
    "    # Parameter space for Decision Tree\n",
    "    params = {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 32),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'class_weight': trial.suggest_categorical('class_weight', [None, 'balanced']),\n",
    "        'random_state': 42,\n",
    "    }\n",
    "    \n",
    "    dt_classifier = DecisionTreeClassifier(**params)\n",
    "\n",
    "    # use cross validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scoring = {\n",
    "        'f1_score': make_scorer(f1_score, zero_division=0),\n",
    "        'accuracy': make_scorer(accuracy_score)\n",
    "    }\n",
    "\n",
    "    # Cross-validate\n",
    "    scores = cross_validate(dt_classifier, X_train, y_train, cv=skf, scoring=scoring)\n",
    "\n",
    "    # defense if nan\n",
    "    mean_f1 = np.nanmean(scores['test_f1_score']) if np.any(np.isnan(scores['test_f1_score'])) else scores['test_f1_score'].mean()\n",
    "    mean_accuracy = np.nanmean(scores['test_accuracy']) if np.any(np.isnan(scores['test_accuracy'])) else scores['test_accuracy'].mean()\n",
    "    \n",
    "    if np.isnan(mean_f1) or np.isnan(mean_accuracy):\n",
    "        return 0.0, 0.0\n",
    "    \n",
    "    return mean_f1, mean_accuracy\n",
    "\n",
    "# Maximize F1-Score and Accuracy\n",
    "study_dt_tuned = optuna.create_study(directions=['maximize', 'maximize'])\n",
    "study_dt_tuned.optimize(objective_dt_tuned, n_trials=100)\n",
    "\n",
    "# save the experiment\n",
    "pareto_dt_solution = study_dt_tuned.best_trials\n",
    "\n",
    "print(\"\\n--- Multi-objective Tuning in Decision Tree ---\")\n",
    "print(\"Pareto Optimal Solutions in Decision Tree:\")\n",
    "for trial in pareto_dt_solution:\n",
    "    print(f\"Trial {trial.number}: F1={trial.values[0]:.4f}, Accuracy={trial.values[1]:.4f}, Params={trial.params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa72410",
   "metadata": {},
   "source": [
    "Params di Trial 52 akan digunakan karena memiliki F1-Score paling tinggi di antara lainnya, yakni 0.1710. F1-Score yang lebih tinggi menunjukkan bahwa model lebih baik dalam menyeimbangkan Precision dan Recall untuk mendeteksi kasus fraud. Meskipun 15% ini juga masih kecil karena memang datanya tidak cukup baik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e006c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to use params from Trial 52\n",
      "F1: 0.1710, Accuracy: 0.8357\n",
      "Params: {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 6, 'min_samples_leaf': 4, 'class_weight': 'balanced'}\n"
     ]
    }
   ],
   "source": [
    "# check params trial 85\n",
    "if 52 < len(study_dt_tuned.trials):\n",
    "    selected_trial_52 = study_dt_tuned.trials[52]\n",
    "    \n",
    "    # store best params\n",
    "    best_params_dt_tuned = selected_trial_52.params\n",
    "    best_f1_dt_tuned = selected_trial_52.values[0]\n",
    "    best_accuracy_dt_tuned = selected_trial_52.values[1]\n",
    "    \n",
    "    # print the result\n",
    "    print(f\"Try to use params from Trial {selected_trial_52.number}\")\n",
    "    print(f'F1: {best_f1_dt_tuned:.4f}, Accuracy: {best_accuracy_dt_tuned:.4f}')\n",
    "    print(f\"Params: {best_params_dt_tuned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1d78df03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Evaluasi Model DT Tuned pada Validation Set:\n",
      "      Metric     Score\n",
      "0   Accuracy  0.800000\n",
      "1        AUC  0.486796\n",
      "2     Recall  0.125000\n",
      "3  Precision  0.041667\n",
      "4         F1  0.062500\n"
     ]
    }
   ],
   "source": [
    "# validation result set valid\n",
    "# fit model with best_params_dt_tuned\n",
    "best_dt_model = DecisionTreeClassifier(**best_params_dt_tuned)\n",
    "best_dt_model.fit(X_train, y_train) \n",
    "\n",
    "# predict\n",
    "y_pred_valid_dt = best_dt_model.predict(X_valid)\n",
    "y_proba_valid_dt = best_dt_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "# get all scores\n",
    "accuracy_valid_dt = accuracy_score(y_valid, y_pred_valid_dt)\n",
    "auc_valid_dt = roc_auc_score(y_valid, y_proba_valid_dt)\n",
    "recall_valid_dt = recall_score(y_valid, y_pred_valid_dt, zero_division=0)\n",
    "precision_valid_dt = precision_score(y_valid, y_pred_valid_dt, zero_division=0)\n",
    "f1_valid_dt = f1_score(y_valid, y_pred_valid_dt, zero_division=0)\n",
    "\n",
    "# create dataframe\n",
    "results_valid_best_params_dt = pd.DataFrame(\n",
    "    {'Metric': ['Accuracy', 'AUC', 'Recall', 'Precision', 'F1'],\n",
    "     'Score': [accuracy_valid_dt, auc_valid_dt, recall_valid_dt, precision_valid_dt, f1_valid_dt]\n",
    "     }\n",
    "    )\n",
    "\n",
    "print(\"Hasil Evaluasi Model DT Tuned pada Validation Set:\")\n",
    "print(results_valid_best_params_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2465ef",
   "metadata": {},
   "source": [
    "## Data SMOTE with XGBoost (xgb) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f4115b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-08-03 23:01:18,236] A new study created in memory with name: no-name-6ffe1b29-52cb-4105-8edd-a082de4f46d8\n",
      "[I 2025-08-03 23:01:19,174] Trial 0 finished with values: [0.0, 0.9414285714285715] and parameters: {'n_estimators': 189, 'learning_rate': 0.0023044637756562446, 'max_depth': 7, 'subsample': 0.7654813824868525, 'colsample_bytree': 0.9398510805239979, 'gamma': 0.46235818051621946, 'reg_alpha': 4.443770900154847, 'reg_lambda': 19.98032230214516, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:01:20,981] Trial 1 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 390, 'learning_rate': 0.00032389218257241356, 'max_depth': 8, 'subsample': 0.9034925049134748, 'colsample_bytree': 0.6419491651782974, 'gamma': 0.5876196982040731, 'reg_alpha': 0.012698514383229456, 'reg_lambda': 0.8694761085803067, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:01:21,634] Trial 2 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 141, 'learning_rate': 0.0030485559443878514, 'max_depth': 8, 'subsample': 0.5548249958633551, 'colsample_bytree': 0.6780567620024095, 'gamma': 0.5574523650242682, 'reg_alpha': 0.46345865949068715, 'reg_lambda': 0.020136593379475622, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:01:22,668] Trial 3 finished with values: [0.016, 0.8971428571428571] and parameters: {'n_estimators': 431, 'learning_rate': 0.0009410946968272537, 'max_depth': 2, 'subsample': 0.71013413118196, 'colsample_bytree': 0.8428112653083316, 'gamma': 0.568582109623785, 'reg_alpha': 5.8112915158306006e-08, 'reg_lambda': 0.7912916336846942, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:01:23,794] Trial 4 finished with values: [0.13131313131313133, 0.9242857142857144] and parameters: {'n_estimators': 237, 'learning_rate': 0.017480780996423872, 'max_depth': 8, 'subsample': 0.8255932211812791, 'colsample_bytree': 0.882380447781357, 'gamma': 0.41927480566317465, 'reg_alpha': 0.0045514011453714545, 'reg_lambda': 0.1269359232503229, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:01:24,713] Trial 5 finished with values: [0.04444444444444444, 0.9400000000000001] and parameters: {'n_estimators': 325, 'learning_rate': 0.021873181522987947, 'max_depth': 3, 'subsample': 0.9775731082529426, 'colsample_bytree': 0.6082985533695524, 'gamma': 0.05918674852969241, 'reg_alpha': 9.2590426958004e-05, 'reg_lambda': 5.7251917839072037e-05, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:01:25,471] Trial 6 finished with values: [0.09858585858585858, 0.9242857142857142] and parameters: {'n_estimators': 304, 'learning_rate': 0.1388633848260537, 'max_depth': 2, 'subsample': 0.5122698838539332, 'colsample_bytree': 0.8313456084407622, 'gamma': 0.6773958657308343, 'reg_alpha': 1.4201812072184101e-08, 'reg_lambda': 3.264950780658059e-06, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:01:26,310] Trial 7 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 192, 'learning_rate': 0.0012168356002786754, 'max_depth': 6, 'subsample': 0.637102634055715, 'colsample_bytree': 0.5756180806701774, 'gamma': 0.8591093409115059, 'reg_alpha': 9.959368393990042e-05, 'reg_lambda': 0.015423918233698512, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:01:26,868] Trial 8 finished with values: [0.0, 0.9485714285714286] and parameters: {'n_estimators': 160, 'learning_rate': 0.008514042563331138, 'max_depth': 4, 'subsample': 0.7554949387432113, 'colsample_bytree': 0.7934767635714572, 'gamma': 0.3031455163162773, 'reg_alpha': 11.791645076472573, 'reg_lambda': 1.0202403898434683e-05, 'min_child_weight': 10}.\n",
      "[I 2025-08-03 23:01:28,154] Trial 9 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 362, 'learning_rate': 0.0010048335957659393, 'max_depth': 6, 'subsample': 0.608762987311013, 'colsample_bytree': 0.6396391231017098, 'gamma': 0.2714161166272835, 'reg_alpha': 4.284193041353323, 'reg_lambda': 0.2605512267160237, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:01:28,743] Trial 10 finished with values: [0.0, 0.9357142857142857] and parameters: {'n_estimators': 264, 'learning_rate': 0.06650580077227564, 'max_depth': 2, 'subsample': 0.8969139490209923, 'colsample_bytree': 0.8549693104492392, 'gamma': 0.6404622485917041, 'reg_alpha': 0.6337111885202699, 'reg_lambda': 0.0009557180792755189, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:01:29,987] Trial 11 finished with values: [0.14415584415584415, 0.9228571428571428] and parameters: {'n_estimators': 350, 'learning_rate': 0.001955587027306534, 'max_depth': 5, 'subsample': 0.9346413590938991, 'colsample_bytree': 0.935138120950715, 'gamma': 0.6209355460485576, 'reg_alpha': 1.2002869814885297, 'reg_lambda': 1.6560647160556892e-07, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:01:30,368] Trial 12 finished with values: [0.04444444444444444, 0.9385714285714286] and parameters: {'n_estimators': 103, 'learning_rate': 0.07634212425053871, 'max_depth': 4, 'subsample': 0.776548019139649, 'colsample_bytree': 0.51542154644062, 'gamma': 0.49756822150524316, 'reg_alpha': 1.196853843336926e-05, 'reg_lambda': 0.07540930511174797, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:01:31,018] Trial 13 finished with values: [0.0808080808080808, 0.9357142857142857] and parameters: {'n_estimators': 119, 'learning_rate': 0.0001297768854166167, 'max_depth': 9, 'subsample': 0.9419558450398806, 'colsample_bytree': 0.8067876540978454, 'gamma': 0.9782769414909204, 'reg_alpha': 0.0016377927121885123, 'reg_lambda': 2.3110643955221684, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:01:32,760] Trial 14 finished with values: [0.0, 0.9442857142857143] and parameters: {'n_estimators': 479, 'learning_rate': 0.00020191501370203486, 'max_depth': 6, 'subsample': 0.9956155610197805, 'colsample_bytree': 0.5791885491110418, 'gamma': 0.043815793553192206, 'reg_alpha': 9.786469567055628e-06, 'reg_lambda': 3.2938905313027624, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:01:34,280] Trial 15 finished with values: [0.03636363636363636, 0.9371428571428572] and parameters: {'n_estimators': 375, 'learning_rate': 0.0006359586691544114, 'max_depth': 6, 'subsample': 0.8504822219984525, 'colsample_bytree': 0.828128351395798, 'gamma': 0.25541593374419425, 'reg_alpha': 5.2184870077086985e-08, 'reg_lambda': 7.0525558608081105e-06, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:01:34,841] Trial 16 finished with values: [0.0, 0.95] and parameters: {'n_estimators': 340, 'learning_rate': 0.05664527002521255, 'max_depth': 3, 'subsample': 0.8977972519520767, 'colsample_bytree': 0.7114880931202257, 'gamma': 0.8824128756240242, 'reg_alpha': 85.31006731295986, 'reg_lambda': 1.4713947472717473e-06, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:01:35,320] Trial 17 finished with values: [0.05310299952599566, 0.6285714285714286] and parameters: {'n_estimators': 224, 'learning_rate': 0.0005887330470205034, 'max_depth': 1, 'subsample': 0.679613173672205, 'colsample_bytree': 0.8972073053334824, 'gamma': 0.7262650563197955, 'reg_alpha': 30.76313546982305, 'reg_lambda': 4.551627838016536e-06, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:01:35,911] Trial 18 finished with values: [0.04942890442890443, 0.7285714285714284] and parameters: {'n_estimators': 311, 'learning_rate': 0.001897116184467386, 'max_depth': 1, 'subsample': 0.5587348221544861, 'colsample_bytree': 0.9561658734389755, 'gamma': 0.5590009244914176, 'reg_alpha': 8.088417137810785e-07, 'reg_lambda': 2.916048731694421, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:01:37,310] Trial 19 finished with values: [0.05429864253393666, 0.9200000000000002] and parameters: {'n_estimators': 189, 'learning_rate': 0.0003841798225353706, 'max_depth': 10, 'subsample': 0.5562830288690475, 'colsample_bytree': 0.9607373977338708, 'gamma': 0.9683842613035851, 'reg_alpha': 7.257764757627758e-06, 'reg_lambda': 0.003251637383815314, 'min_child_weight': 2}.\n",
      "[I 2025-08-03 23:01:39,745] Trial 20 finished with values: [0.04444444444444444, 0.9414285714285715] and parameters: {'n_estimators': 485, 'learning_rate': 0.003671022294520586, 'max_depth': 7, 'subsample': 0.6856686365886853, 'colsample_bytree': 0.6114858262323721, 'gamma': 0.6825865725976717, 'reg_alpha': 0.007916893261527782, 'reg_lambda': 4.794538234463979e-07, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:01:40,794] Trial 21 finished with values: [0.0, 0.9328571428571429] and parameters: {'n_estimators': 446, 'learning_rate': 0.0007143596508810422, 'max_depth': 2, 'subsample': 0.7095592036379013, 'colsample_bytree': 0.6380358033767479, 'gamma': 0.8753014853880151, 'reg_alpha': 25.61158020650273, 'reg_lambda': 3.9992231569249137, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:01:41,368] Trial 22 finished with values: [0.04182020877673052, 0.6814285714285713] and parameters: {'n_estimators': 234, 'learning_rate': 0.00011840255545664812, 'max_depth': 1, 'subsample': 0.6418162338404729, 'colsample_bytree': 0.9423937643299137, 'gamma': 0.5279745420935803, 'reg_alpha': 2.2484835469358147e-06, 'reg_lambda': 0.004412690255295304, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:01:42,236] Trial 23 finished with values: [0.03636363636363636, 0.9342857142857144] and parameters: {'n_estimators': 272, 'learning_rate': 0.03127842535518483, 'max_depth': 7, 'subsample': 0.8748127012780341, 'colsample_bytree': 0.5281052114918894, 'gamma': 0.759666837190704, 'reg_alpha': 8.958177494408915e-08, 'reg_lambda': 0.8149687806549311, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:01:42,454] Trial 24 finished with values: [0.0, 0.95] and parameters: {'n_estimators': 66, 'learning_rate': 0.12221081192954712, 'max_depth': 7, 'subsample': 0.6066377047895773, 'colsample_bytree': 0.9113685851228608, 'gamma': 0.8426564287487066, 'reg_alpha': 89.04364264463771, 'reg_lambda': 0.03767424029464611, 'min_child_weight': 1}.\n",
      "[I 2025-08-03 23:01:43,915] Trial 25 finished with values: [0.0, 0.9485714285714286] and parameters: {'n_estimators': 378, 'learning_rate': 0.00022243782673056736, 'max_depth': 8, 'subsample': 0.5521914355606254, 'colsample_bytree': 0.6298732887864733, 'gamma': 0.7178572283012304, 'reg_alpha': 0.009221486753912107, 'reg_lambda': 3.236151969925051e-05, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:01:44,465] Trial 26 finished with values: [0.03636363636363636, 0.9385714285714286] and parameters: {'n_estimators': 100, 'learning_rate': 0.015910621766854913, 'max_depth': 9, 'subsample': 0.7748222569456051, 'colsample_bytree': 0.689354237121635, 'gamma': 0.6033693879227496, 'reg_alpha': 1.2317488286216692e-08, 'reg_lambda': 3.5831660947915333e-07, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:01:45,254] Trial 27 finished with values: [0.045628856193640245, 0.7457142857142858] and parameters: {'n_estimators': 430, 'learning_rate': 0.0023356323179008613, 'max_depth': 1, 'subsample': 0.6529085810906012, 'colsample_bytree': 0.5956367639575191, 'gamma': 0.6433718091149987, 'reg_alpha': 1.548334881637329e-05, 'reg_lambda': 0.7593000309900969, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:01:45,759] Trial 28 finished with values: [0.0946969696969697, 0.9228571428571429] and parameters: {'n_estimators': 68, 'learning_rate': 0.02949048653992273, 'max_depth': 8, 'subsample': 0.5786766494100462, 'colsample_bytree': 0.9596853279291746, 'gamma': 0.24686901576962372, 'reg_alpha': 1.336296759123354e-08, 'reg_lambda': 0.003922030338314865, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:01:46,878] Trial 29 finished with values: [0.11483253588516747, 0.9271428571428573] and parameters: {'n_estimators': 253, 'learning_rate': 0.028640158939658995, 'max_depth': 10, 'subsample': 0.5668080174054861, 'colsample_bytree': 0.7296826075759877, 'gamma': 0.7665788973647405, 'reg_alpha': 1.4566508658102574e-05, 'reg_lambda': 2.28909120001162e-08, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:01:47,153] Trial 30 finished with values: [0.05293131988784163, 0.6699999999999999] and parameters: {'n_estimators': 89, 'learning_rate': 0.00015083170768594002, 'max_depth': 1, 'subsample': 0.8666130468173421, 'colsample_bytree': 0.6118258482370733, 'gamma': 0.6569947277679705, 'reg_alpha': 10.99167621271259, 'reg_lambda': 64.15128056930875, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:01:47,989] Trial 31 finished with values: [0.042105263157894736, 0.9328571428571429] and parameters: {'n_estimators': 138, 'learning_rate': 0.0741704676519322, 'max_depth': 3, 'subsample': 0.9289014619375686, 'colsample_bytree': 0.5388753641135963, 'gamma': 0.7069000910385936, 'reg_alpha': 0.3018916645148019, 'reg_lambda': 8.704610112313505, 'min_child_weight': 2}.\n",
      "[I 2025-08-03 23:01:49,578] Trial 32 finished with values: [0.04444444444444444, 0.9414285714285715] and parameters: {'n_estimators': 275, 'learning_rate': 0.005074351781638781, 'max_depth': 8, 'subsample': 0.8459582774430183, 'colsample_bytree': 0.6419511941734789, 'gamma': 0.5355389236566817, 'reg_alpha': 7.117722899928874e-07, 'reg_lambda': 5.1182398019437334e-05, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:01:50,276] Trial 33 finished with values: [0.059893048128342244, 0.9271428571428573] and parameters: {'n_estimators': 116, 'learning_rate': 0.03933147560571383, 'max_depth': 10, 'subsample': 0.5332136141001996, 'colsample_bytree': 0.8083341925666132, 'gamma': 0.157303176491972, 'reg_alpha': 1.2384247045910252e-06, 'reg_lambda': 4.6252191597322816e-05, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:01:51,386] Trial 34 finished with values: [0.11445887445887445, 0.9271428571428573] and parameters: {'n_estimators': 314, 'learning_rate': 0.05195086195805058, 'max_depth': 3, 'subsample': 0.7315160305582069, 'colsample_bytree': 0.917374481103154, 'gamma': 0.45061999368555106, 'reg_alpha': 0.2550785754591309, 'reg_lambda': 1.5302260148148015e-06, 'min_child_weight': 10}.\n",
      "[I 2025-08-03 23:01:52,567] Trial 35 finished with values: [0.013793103448275862, 0.8985714285714286] and parameters: {'n_estimators': 348, 'learning_rate': 0.00010514312855908884, 'max_depth': 2, 'subsample': 0.5831837032036885, 'colsample_bytree': 0.7561875946300407, 'gamma': 0.14613020456062953, 'reg_alpha': 2.8790416419661487e-06, 'reg_lambda': 0.00039402908514372384, 'min_child_weight': 1}.\n",
      "[I 2025-08-03 23:01:54,152] Trial 36 finished with values: [0.06797385620915034, 0.9342857142857144] and parameters: {'n_estimators': 280, 'learning_rate': 0.0030550916036230853, 'max_depth': 5, 'subsample': 0.7255663721231859, 'colsample_bytree': 0.7545063277309949, 'gamma': 0.21446125941544092, 'reg_alpha': 8.53903775939275e-05, 'reg_lambda': 3.1234625977880357e-05, 'min_child_weight': 1}.\n",
      "[I 2025-08-03 23:01:54,821] Trial 37 finished with values: [0.05310299952599566, 0.6285714285714286] and parameters: {'n_estimators': 255, 'learning_rate': 0.00011471997428396534, 'max_depth': 1, 'subsample': 0.6627884137961054, 'colsample_bytree': 0.9910925760135256, 'gamma': 0.8737998548991062, 'reg_alpha': 19.76584640648077, 'reg_lambda': 0.0007148356530968286, 'min_child_weight': 1}.\n",
      "[I 2025-08-03 23:01:55,384] Trial 38 finished with values: [0.043476523476523476, 0.7285714285714284] and parameters: {'n_estimators': 217, 'learning_rate': 0.0034544551946783285, 'max_depth': 1, 'subsample': 0.7387138255208645, 'colsample_bytree': 0.8599322584453531, 'gamma': 0.7518409014392349, 'reg_alpha': 9.890892554530695e-07, 'reg_lambda': 0.3218125017893519, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:01:56,616] Trial 39 finished with values: [0.08253968253968254, 0.9314285714285713] and parameters: {'n_estimators': 428, 'learning_rate': 0.010464103617045483, 'max_depth': 3, 'subsample': 0.650062686126259, 'colsample_bytree': 0.7824477412387172, 'gamma': 0.5552092249449411, 'reg_alpha': 0.0028279953712552885, 'reg_lambda': 0.00010426414192538399, 'min_child_weight': 2}.\n",
      "[I 2025-08-03 23:01:57,393] Trial 40 finished with values: [0.04182020877673052, 0.6914285714285715] and parameters: {'n_estimators': 264, 'learning_rate': 0.00016548477132094822, 'max_depth': 1, 'subsample': 0.9644658241198822, 'colsample_bytree': 0.5789588184047723, 'gamma': 0.4736253150771166, 'reg_alpha': 1.901929502278729e-07, 'reg_lambda': 0.01930231401186809, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:01:58,302] Trial 41 finished with values: [0.0, 0.9228571428571429] and parameters: {'n_estimators': 196, 'learning_rate': 0.0002218300353666359, 'max_depth': 4, 'subsample': 0.7670377864448779, 'colsample_bytree': 0.9859981330484289, 'gamma': 0.12073811530877032, 'reg_alpha': 0.8378200484403038, 'reg_lambda': 0.0008469963773148701, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:01:59,255] Trial 42 finished with values: [0.02222222222222222, 0.937142857142857] and parameters: {'n_estimators': 186, 'learning_rate': 0.0021375806988001476, 'max_depth': 6, 'subsample': 0.5296713530576501, 'colsample_bytree': 0.7279925962532261, 'gamma': 0.3459781126762451, 'reg_alpha': 4.583630708733924e-08, 'reg_lambda': 0.15707744542472848, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:01:59,650] Trial 43 finished with values: [0.0, 0.9371428571428572] and parameters: {'n_estimators': 75, 'learning_rate': 0.005250667341205943, 'max_depth': 7, 'subsample': 0.656278823392128, 'colsample_bytree': 0.7232318679049675, 'gamma': 0.6610150930846072, 'reg_alpha': 31.878475132763946, 'reg_lambda': 0.0020028235048319613, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:02:00,161] Trial 44 finished with values: [0.06105263157894737, 0.93] and parameters: {'n_estimators': 156, 'learning_rate': 0.11293202586520883, 'max_depth': 2, 'subsample': 0.5932455794187148, 'colsample_bytree': 0.6808563409871804, 'gamma': 0.5545963997288172, 'reg_alpha': 0.19613046024691208, 'reg_lambda': 9.223748239581031, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:02:00,703] Trial 45 finished with values: [0.0, 0.9442857142857143] and parameters: {'n_estimators': 108, 'learning_rate': 0.0041926516802302085, 'max_depth': 6, 'subsample': 0.8365028758893236, 'colsample_bytree': 0.5980760705407725, 'gamma': 0.01079755741655053, 'reg_alpha': 4.509423846310804, 'reg_lambda': 5.779907403868197e-06, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:02:01,197] Trial 46 finished with values: [0.037121212121212124, 0.8214285714285715] and parameters: {'n_estimators': 246, 'learning_rate': 0.018756609007875253, 'max_depth': 1, 'subsample': 0.7580595442584038, 'colsample_bytree': 0.5313445931628904, 'gamma': 0.7696178254351269, 'reg_alpha': 0.011689604869199828, 'reg_lambda': 84.70330158885163, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:02:01,678] Trial 47 finished with values: [0.0, 0.9442857142857143] and parameters: {'n_estimators': 106, 'learning_rate': 0.00017793884867156165, 'max_depth': 6, 'subsample': 0.5625165283636931, 'colsample_bytree': 0.9062882998381165, 'gamma': 0.11365172877043328, 'reg_alpha': 8.224702178879262, 'reg_lambda': 14.453105510384392, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:02:02,390] Trial 48 finished with values: [0.04047142057862725, 0.6728571428571428] and parameters: {'n_estimators': 356, 'learning_rate': 0.00036645389234210026, 'max_depth': 1, 'subsample': 0.6141952970612962, 'colsample_bytree': 0.9020029652133413, 'gamma': 0.8144640832388468, 'reg_alpha': 9.236544613906859e-08, 'reg_lambda': 1.43272050627199, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:02:02,603] Trial 49 finished with values: [0.01951219512195122, 0.8142857142857143] and parameters: {'n_estimators': 50, 'learning_rate': 0.09614175794494513, 'max_depth': 1, 'subsample': 0.6225961575147847, 'colsample_bytree': 0.7694614104872096, 'gamma': 0.9736535855675483, 'reg_alpha': 0.7774209505656149, 'reg_lambda': 1.5581852749043755e-06, 'min_child_weight': 2}.\n",
      "[I 2025-08-03 23:02:03,418] Trial 50 finished with values: [0.045628856193640245, 0.7457142857142858] and parameters: {'n_estimators': 430, 'learning_rate': 0.0023356323179008613, 'max_depth': 1, 'subsample': 0.6529085810906012, 'colsample_bytree': 0.5956367639575191, 'gamma': 0.6433718091149987, 'reg_alpha': 1.548334881637329e-05, 'reg_lambda': 0.7593000309900969, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:02:03,652] Trial 51 finished with values: [0.0, 0.95] and parameters: {'n_estimators': 66, 'learning_rate': 0.12221081192954712, 'max_depth': 9, 'subsample': 0.6066377047895773, 'colsample_bytree': 0.689354237121635, 'gamma': 0.8426564287487066, 'reg_alpha': 89.04364264463771, 'reg_lambda': 0.0014087528111139261, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:02:04,124] Trial 52 finished with values: [0.05310299952599566, 0.6285714285714286] and parameters: {'n_estimators': 224, 'learning_rate': 0.0010048335957659393, 'max_depth': 1, 'subsample': 0.608762987311013, 'colsample_bytree': 0.8972073053334824, 'gamma': 0.7262650563197955, 'reg_alpha': 30.76313546982305, 'reg_lambda': 0.020412786438559503, 'min_child_weight': 2}.\n",
      "[I 2025-08-03 23:02:05,243] Trial 53 finished with values: [0.09047619047619047, 0.9199999999999999] and parameters: {'n_estimators': 485, 'learning_rate': 0.19431285067923879, 'max_depth': 7, 'subsample': 0.637102634055715, 'colsample_bytree': 0.6114858262323721, 'gamma': 0.6825865725976717, 'reg_alpha': 0.007916893261527782, 'reg_lambda': 0.015423918233698512, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:02:06,672] Trial 54 finished with values: [0.14415584415584415, 0.9228571428571428] and parameters: {'n_estimators': 390, 'learning_rate': 0.00032389218257241356, 'max_depth': 5, 'subsample': 0.9034925049134748, 'colsample_bytree': 0.9681677864619868, 'gamma': 0.6209355460485576, 'reg_alpha': 0.012698514383229456, 'reg_lambda': 1.6560647160556892e-07, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:02:07,171] Trial 55 finished with values: [0.03822200787718029, 0.7171428571428571] and parameters: {'n_estimators': 264, 'learning_rate': 0.001955587027306534, 'max_depth': 1, 'subsample': 0.9346413590938991, 'colsample_bytree': 0.5789588184047723, 'gamma': 0.6209355460485576, 'reg_alpha': 1.901929502278729e-07, 'reg_lambda': 1.6560647160556892e-07, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:02:07,611] Trial 56 finished with values: [0.0784688995215311, 0.9342857142857144] and parameters: {'n_estimators': 141, 'learning_rate': 0.0741704676519322, 'max_depth': 3, 'subsample': 0.8748127012780341, 'colsample_bytree': 0.5281052114918894, 'gamma': 0.7069000910385936, 'reg_alpha': 8.958177494408915e-08, 'reg_lambda': 8.704610112313505, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:02:07,834] Trial 57 finished with values: [0.0, 0.95] and parameters: {'n_estimators': 66, 'learning_rate': 0.12221081192954712, 'max_depth': 7, 'subsample': 0.7654813824868525, 'colsample_bytree': 0.9113685851228608, 'gamma': 0.8426564287487066, 'reg_alpha': 89.04364264463771, 'reg_lambda': 19.98032230214516, 'min_child_weight': 10}.\n",
      "[I 2025-08-03 23:02:08,331] Trial 58 finished with values: [0.05310299952599566, 0.6285714285714286] and parameters: {'n_estimators': 224, 'learning_rate': 0.0005887330470205034, 'max_depth': 1, 'subsample': 0.679613173672205, 'colsample_bytree': 0.8972073053334824, 'gamma': 0.7262650563197955, 'reg_alpha': 30.76313546982305, 'reg_lambda': 4.6761342372180196e-08, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:02:10,402] Trial 59 finished with values: [0.03636363636363636, 0.9371428571428572] and parameters: {'n_estimators': 485, 'learning_rate': 0.003671022294520586, 'max_depth': 8, 'subsample': 0.6856686365886853, 'colsample_bytree': 0.6114858262323721, 'gamma': 0.5574523650242682, 'reg_alpha': 0.46345865949068715, 'reg_lambda': 5.4408628430597916e-05, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:02:11,227] Trial 60 finished with values: [0.0, 0.9371428571428572] and parameters: {'n_estimators': 189, 'learning_rate': 0.0023044637756562446, 'max_depth': 6, 'subsample': 0.5296713530576501, 'colsample_bytree': 0.9157628534938043, 'gamma': 0.3459781126762451, 'reg_alpha': 4.443770900154847, 'reg_lambda': 0.15707744542472848, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:02:12,846] Trial 61 finished with values: [0.0, 0.9485714285714286] and parameters: {'n_estimators': 362, 'learning_rate': 0.0010048335957659393, 'max_depth': 8, 'subsample': 0.5521914355606254, 'colsample_bytree': 0.6298732887864733, 'gamma': 0.7178572283012304, 'reg_alpha': 4.284193041353323, 'reg_lambda': 3.236151969925051e-05, 'min_child_weight': 10}.\n",
      "[I 2025-08-03 23:02:14,462] Trial 62 finished with values: [0.04, 0.93] and parameters: {'n_estimators': 275, 'learning_rate': 0.005250667341205943, 'max_depth': 7, 'subsample': 0.8459582774430183, 'colsample_bytree': 0.7232318679049675, 'gamma': 0.5355389236566817, 'reg_alpha': 7.117722899928874e-07, 'reg_lambda': 0.0020028235048319613, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:02:15,008] Trial 63 finished with values: [0.0, 0.9485714285714286] and parameters: {'n_estimators': 100, 'learning_rate': 0.015910621766854913, 'max_depth': 3, 'subsample': 0.7315160305582069, 'colsample_bytree': 0.5759266397579377, 'gamma': 0.5446257783883615, 'reg_alpha': 0.2550785754591309, 'reg_lambda': 3.5831660947915333e-07, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:02:16,093] Trial 64 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 141, 'learning_rate': 0.0030485559443878514, 'max_depth': 8, 'subsample': 0.5548249958633551, 'colsample_bytree': 0.6780567620024095, 'gamma': 0.5574523650242682, 'reg_alpha': 0.46345865949068715, 'reg_lambda': 0.020136593379475622, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:02:17,284] Trial 65 finished with values: [0.0, 0.9371428571428572] and parameters: {'n_estimators': 186, 'learning_rate': 0.0021375806988001476, 'max_depth': 6, 'subsample': 0.5296713530576501, 'colsample_bytree': 0.8866310281727667, 'gamma': 0.3459781126762451, 'reg_alpha': 4.583630708733924e-08, 'reg_lambda': 0.15707744542472848, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:02:19,880] Trial 66 finished with values: [0.03636363636363636, 0.9371428571428572] and parameters: {'n_estimators': 375, 'learning_rate': 0.0006359586691544114, 'max_depth': 6, 'subsample': 0.8504822219984525, 'colsample_bytree': 0.828128351395798, 'gamma': 0.25541593374419425, 'reg_alpha': 5.2184870077086985e-08, 'reg_lambda': 7.0525558608081105e-06, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:02:20,298] Trial 67 finished with values: [0.0, 0.95] and parameters: {'n_estimators': 138, 'learning_rate': 0.03933147560571383, 'max_depth': 3, 'subsample': 0.5332136141001996, 'colsample_bytree': 0.5388753641135963, 'gamma': 0.2416888973912319, 'reg_alpha': 68.83245546889012, 'reg_lambda': 3.939326309372853e-07, 'min_child_weight': 2}.\n",
      "[I 2025-08-03 23:02:21,846] Trial 68 finished with values: [0.03333333333333333, 0.9442857142857143] and parameters: {'n_estimators': 246, 'learning_rate': 0.018756609007875253, 'max_depth': 6, 'subsample': 0.7580595442584038, 'colsample_bytree': 0.7279925962532261, 'gamma': 0.7696178254351269, 'reg_alpha': 4.583630708733924e-08, 'reg_lambda': 84.70330158885163, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:02:22,443] Trial 69 finished with values: [0.013793103448275862, 0.877142857142857] and parameters: {'n_estimators': 156, 'learning_rate': 0.0001297768854166167, 'max_depth': 2, 'subsample': 0.9419558450398806, 'colsample_bytree': 0.6808563409871804, 'gamma': 0.5545963997288172, 'reg_alpha': 0.0016377927121885123, 'reg_lambda': 2.3110643955221684, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:02:24,295] Trial 70 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 275, 'learning_rate': 0.0012168356002786754, 'max_depth': 8, 'subsample': 0.637102634055715, 'colsample_bytree': 0.5756180806701774, 'gamma': 0.5355389236566817, 'reg_alpha': 9.959368393990042e-05, 'reg_lambda': 0.015423918233698512, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:02:26,474] Trial 71 finished with values: [0.09379953379953379, 0.9214285714285715] and parameters: {'n_estimators': 378, 'learning_rate': 0.00022243782673056736, 'max_depth': 8, 'subsample': 0.6066377047895773, 'colsample_bytree': 0.9113685851228608, 'gamma': 0.8426564287487066, 'reg_alpha': 0.009221486753912107, 'reg_lambda': 0.03767424029464611, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:02:28,408] Trial 72 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 390, 'learning_rate': 0.00032389218257241356, 'max_depth': 8, 'subsample': 0.9034925049134748, 'colsample_bytree': 0.6419491651782974, 'gamma': 0.5876196982040731, 'reg_alpha': 0.0016377927121885123, 'reg_lambda': 0.8694761085803067, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:02:28,981] Trial 73 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 108, 'learning_rate': 0.0041926516802302085, 'max_depth': 6, 'subsample': 0.6604666242145663, 'colsample_bytree': 0.5980760705407725, 'gamma': 0.01079755741655053, 'reg_alpha': 4.509423846310804, 'reg_lambda': 0.8694761085803067, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:02:29,513] Trial 74 finished with values: [0.03072586328400282, 0.7899999999999999] and parameters: {'n_estimators': 217, 'learning_rate': 0.015910621766854913, 'max_depth': 1, 'subsample': 0.7387138255208645, 'colsample_bytree': 0.8599322584453531, 'gamma': 0.6033693879227496, 'reg_alpha': 9.890892554530695e-07, 'reg_lambda': 3.5831660947915333e-07, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:02:31,256] Trial 75 finished with values: [0.0, 0.9385714285714286] and parameters: {'n_estimators': 362, 'learning_rate': 0.00010514312855908884, 'max_depth': 6, 'subsample': 0.608762987311013, 'colsample_bytree': 0.7561875946300407, 'gamma': 0.14613020456062953, 'reg_alpha': 2.8790416419661487e-06, 'reg_lambda': 0.2605512267160237, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:02:31,752] Trial 76 finished with values: [0.039949403288786225, 0.7285714285714285] and parameters: {'n_estimators': 186, 'learning_rate': 0.0021375806988001476, 'max_depth': 1, 'subsample': 0.5296713530576501, 'colsample_bytree': 0.7694614104872096, 'gamma': 0.3459781126762451, 'reg_alpha': 4.583630708733924e-08, 'reg_lambda': 0.15707744542472848, 'min_child_weight': 2}.\n",
      "[I 2025-08-03 23:02:32,583] Trial 77 finished with values: [0.03636363636363636, 0.93] and parameters: {'n_estimators': 119, 'learning_rate': 0.0001297768854166167, 'max_depth': 6, 'subsample': 0.9419558450398806, 'colsample_bytree': 0.7539215313813528, 'gamma': 0.9782769414909204, 'reg_alpha': 0.7208444819796945, 'reg_lambda': 0.015423918233698512, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:02:33,674] Trial 78 finished with values: [0.0808080808080808, 0.9328571428571429] and parameters: {'n_estimators': 272, 'learning_rate': 0.03127842535518483, 'max_depth': 4, 'subsample': 0.8748127012780341, 'colsample_bytree': 0.5281052114918894, 'gamma': 0.49756822150524316, 'reg_alpha': 1.196853843336926e-05, 'reg_lambda': 0.07540930511174797, 'min_child_weight': 10}.\n",
      "[I 2025-08-03 23:02:35,172] Trial 79 finished with values: [0.0, 0.9485714285714286] and parameters: {'n_estimators': 314, 'learning_rate': 0.0030485559443878514, 'max_depth': 3, 'subsample': 0.7315160305582069, 'colsample_bytree': 0.6780567620024095, 'gamma': 0.5574523650242682, 'reg_alpha': 0.2550785754591309, 'reg_lambda': 0.020136593379475622, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:02:36,071] Trial 80 finished with values: [0.0, 0.95] and parameters: {'n_estimators': 340, 'learning_rate': 0.028640158939658995, 'max_depth': 10, 'subsample': 0.5668080174054861, 'colsample_bytree': 0.7114880931202257, 'gamma': 0.7665788973647405, 'reg_alpha': 85.31006731295986, 'reg_lambda': 1.4713947472717473e-06, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:02:37,188] Trial 81 finished with values: [0.013793103448275862, 0.9214285714285714] and parameters: {'n_estimators': 315, 'learning_rate': 0.0010048335957659393, 'max_depth': 2, 'subsample': 0.71013413118196, 'colsample_bytree': 0.8428112653083316, 'gamma': 0.568582109623785, 'reg_alpha': 5.8112915158306006e-08, 'reg_lambda': 0.2605512267160237, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:02:38,062] Trial 82 finished with values: [0.04, 0.9342857142857144] and parameters: {'n_estimators': 141, 'learning_rate': 0.0003300912490185304, 'max_depth': 8, 'subsample': 0.9419558450398806, 'colsample_bytree': 0.8067876540978454, 'gamma': 0.2424657399830603, 'reg_alpha': 0.46345865949068715, 'reg_lambda': 0.020136593379475622, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:02:39,337] Trial 83 finished with values: [0.05210084033613445, 0.9157142857142858] and parameters: {'n_estimators': 189, 'learning_rate': 0.0023044637756562446, 'max_depth': 8, 'subsample': 0.7654813824868525, 'colsample_bytree': 0.9398510805239979, 'gamma': 0.46235818051621946, 'reg_alpha': 0.012698514383229456, 'reg_lambda': 0.8694761085803067, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:02:40,146] Trial 84 finished with values: [0.04, 0.9371428571428572] and parameters: {'n_estimators': 160, 'learning_rate': 0.008514042563331138, 'max_depth': 6, 'subsample': 0.7554949387432113, 'colsample_bytree': 0.7934767635714572, 'gamma': 0.8591093409115059, 'reg_alpha': 9.959368393990042e-05, 'reg_lambda': 0.015423918233698512, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:02:40,814] Trial 85 finished with values: [0.03827751196172249, 0.7228571428571429] and parameters: {'n_estimators': 141, 'learning_rate': 0.00022243782673056736, 'max_depth': 1, 'subsample': 0.5548249958633551, 'colsample_bytree': 0.6298732887864733, 'gamma': 0.7155437332746668, 'reg_alpha': 0.46345865949068715, 'reg_lambda': 0.020136593379475622, 'min_child_weight': 8}.\n",
      "[I 2025-08-03 23:02:41,440] Trial 86 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 100, 'learning_rate': 0.0010048335957659393, 'max_depth': 5, 'subsample': 0.7748222569456051, 'colsample_bytree': 0.6396391231017098, 'gamma': 0.6033693879227496, 'reg_alpha': 1.120124910978577e-07, 'reg_lambda': 3.5831660947915333e-07, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:02:41,881] Trial 87 finished with values: [0.06713286713286713, 0.9285714285714286] and parameters: {'n_estimators': 66, 'learning_rate': 0.0041926516802302085, 'max_depth': 6, 'subsample': 0.8365028758893236, 'colsample_bytree': 0.9113685851228608, 'gamma': 0.2215580920692144, 'reg_alpha': 4.509423846310804, 'reg_lambda': 5.779907403868197e-06, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:02:42,278] Trial 88 finished with values: [0.0, 0.9428571428571428] and parameters: {'n_estimators': 89, 'learning_rate': 0.00015083170768594002, 'max_depth': 3, 'subsample': 0.8666130468173421, 'colsample_bytree': 0.6118258482370733, 'gamma': 0.6569947277679705, 'reg_alpha': 10.99167621271259, 'reg_lambda': 1.4713947472717473e-06, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:02:43,670] Trial 89 finished with values: [0.12698412698412698, 0.9314285714285713] and parameters: {'n_estimators': 428, 'learning_rate': 0.010464103617045483, 'max_depth': 3, 'subsample': 0.7954202306320902, 'colsample_bytree': 0.7824477412387172, 'gamma': 0.5552092249449411, 'reg_alpha': 0.0028279953712552885, 'reg_lambda': 0.00010426414192538399, 'min_child_weight': 2}.\n",
      "[I 2025-08-03 23:02:46,291] Trial 90 finished with values: [0.03333333333333333, 0.9285714285714286] and parameters: {'n_estimators': 237, 'learning_rate': 0.017480780996423872, 'max_depth': 8, 'subsample': 0.9775731082529426, 'colsample_bytree': 0.6082985533695524, 'gamma': 0.05918674852969241, 'reg_alpha': 9.2590426958004e-05, 'reg_lambda': 0.1269359232503229, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:02:47,358] Trial 91 finished with values: [0.0, 0.9442857142857143] and parameters: {'n_estimators': 108, 'learning_rate': 0.0041926516802302085, 'max_depth': 6, 'subsample': 0.8365028758893236, 'colsample_bytree': 0.5980760705407725, 'gamma': 0.24686901576962372, 'reg_alpha': 4.509423846310804, 'reg_lambda': 0.003922030338314865, 'min_child_weight': 4}.\n",
      "[I 2025-08-03 23:02:49,277] Trial 92 finished with values: [0.04444444444444444, 0.9414285714285715] and parameters: {'n_estimators': 275, 'learning_rate': 0.005074351781638781, 'max_depth': 8, 'subsample': 0.8459582774430183, 'colsample_bytree': 0.6419511941734789, 'gamma': 0.5355389236566817, 'reg_alpha': 7.117722899928874e-07, 'reg_lambda': 5.1182398019437334e-05, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:02:50,126] Trial 93 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 186, 'learning_rate': 0.0023044637756562446, 'max_depth': 6, 'subsample': 0.7596760659970905, 'colsample_bytree': 0.7279925962532261, 'gamma': 0.3459781126762451, 'reg_alpha': 4.443770900154847, 'reg_lambda': 19.98032230214516, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:02:50,796] Trial 94 finished with values: [0.0, 0.9428571428571428] and parameters: {'n_estimators': 116, 'learning_rate': 0.00022243782673056736, 'max_depth': 10, 'subsample': 0.5521914355606254, 'colsample_bytree': 0.8083341925666132, 'gamma': 0.7178572283012304, 'reg_alpha': 0.009221486753912107, 'reg_lambda': 3.236151969925051e-05, 'min_child_weight': 9}.\n",
      "[I 2025-08-03 23:02:51,608] Trial 95 finished with values: [0.0, 0.95] and parameters: {'n_estimators': 340, 'learning_rate': 0.05664527002521255, 'max_depth': 3, 'subsample': 0.8977972519520767, 'colsample_bytree': 0.7114880931202257, 'gamma': 0.8824128756240242, 'reg_alpha': 85.31006731295986, 'reg_lambda': 1.5302260148148015e-06, 'min_child_weight': 6}.\n",
      "[I 2025-08-03 23:02:52,351] Trial 96 finished with values: [0.018604651162790697, 0.89] and parameters: {'n_estimators': 264, 'learning_rate': 0.0001297768854166167, 'max_depth': 2, 'subsample': 0.9419558450398806, 'colsample_bytree': 0.7706104131365468, 'gamma': 0.9782769414909204, 'reg_alpha': 0.6337111885202699, 'reg_lambda': 0.01222277423961944, 'min_child_weight': 7}.\n",
      "[I 2025-08-03 23:02:53,005] Trial 97 finished with values: [0.08888888888888888, 0.9314285714285715] and parameters: {'n_estimators': 253, 'learning_rate': 0.15820282261307023, 'max_depth': 10, 'subsample': 0.5668080174054861, 'colsample_bytree': 0.7296826075759877, 'gamma': 0.4128556103059402, 'reg_alpha': 4.443770900154847, 'reg_lambda': 2.28909120001162e-08, 'min_child_weight': 3}.\n",
      "[I 2025-08-03 23:02:53,716] Trial 98 finished with values: [0.04, 0.9385714285714286] and parameters: {'n_estimators': 100, 'learning_rate': 0.015910621766854913, 'max_depth': 9, 'subsample': 0.8930871904754416, 'colsample_bytree': 0.689354237121635, 'gamma': 0.6033693879227496, 'reg_alpha': 1.2317488286216692e-08, 'reg_lambda': 3.5831660947915333e-07, 'min_child_weight': 5}.\n",
      "[I 2025-08-03 23:02:57,085] Trial 99 finished with values: [0.0, 0.9457142857142857] and parameters: {'n_estimators': 479, 'learning_rate': 0.0003841798225353706, 'max_depth': 10, 'subsample': 0.5562830288690475, 'colsample_bytree': 0.5791885491110418, 'gamma': 0.043815793553192206, 'reg_alpha': 7.257764757627758e-06, 'reg_lambda': 0.003251637383815314, 'min_child_weight': 7}.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Multi-objective Tuning in XGBoost ---\n",
      "Pareto Optimal Solutions in XGBoost:\n",
      "  Trial 4: F1=0.1313, Accuracy=0.9243, Params={'n_estimators': 237, 'learning_rate': 0.017480780996423872, 'max_depth': 8, 'subsample': 0.8255932211812791, 'colsample_bytree': 0.882380447781357, 'gamma': 0.41927480566317465, 'reg_alpha': 0.0045514011453714545, 'reg_lambda': 0.1269359232503229, 'min_child_weight': 7}\n",
      "  Trial 11: F1=0.1442, Accuracy=0.9229, Params={'n_estimators': 350, 'learning_rate': 0.001955587027306534, 'max_depth': 5, 'subsample': 0.9346413590938991, 'colsample_bytree': 0.935138120950715, 'gamma': 0.6209355460485576, 'reg_alpha': 1.2002869814885297, 'reg_lambda': 1.6560647160556892e-07, 'min_child_weight': 8}\n",
      "  Trial 13: F1=0.0808, Accuracy=0.9357, Params={'n_estimators': 119, 'learning_rate': 0.0001297768854166167, 'max_depth': 9, 'subsample': 0.9419558450398806, 'colsample_bytree': 0.8067876540978454, 'gamma': 0.9782769414909204, 'reg_alpha': 0.0016377927121885123, 'reg_lambda': 2.3110643955221684, 'min_child_weight': 7}\n",
      "  Trial 16: F1=0.0000, Accuracy=0.9500, Params={'n_estimators': 340, 'learning_rate': 0.05664527002521255, 'max_depth': 3, 'subsample': 0.8977972519520767, 'colsample_bytree': 0.7114880931202257, 'gamma': 0.8824128756240242, 'reg_alpha': 85.31006731295986, 'reg_lambda': 1.4713947472717473e-06, 'min_child_weight': 6}\n",
      "  Trial 20: F1=0.0444, Accuracy=0.9414, Params={'n_estimators': 485, 'learning_rate': 0.003671022294520586, 'max_depth': 7, 'subsample': 0.6856686365886853, 'colsample_bytree': 0.6114858262323721, 'gamma': 0.6825865725976717, 'reg_alpha': 0.007916893261527782, 'reg_lambda': 4.794538234463979e-07, 'min_child_weight': 3}\n",
      "  Trial 24: F1=0.0000, Accuracy=0.9500, Params={'n_estimators': 66, 'learning_rate': 0.12221081192954712, 'max_depth': 7, 'subsample': 0.6066377047895773, 'colsample_bytree': 0.9113685851228608, 'gamma': 0.8426564287487066, 'reg_alpha': 89.04364264463771, 'reg_lambda': 0.03767424029464611, 'min_child_weight': 1}\n",
      "  Trial 32: F1=0.0444, Accuracy=0.9414, Params={'n_estimators': 275, 'learning_rate': 0.005074351781638781, 'max_depth': 8, 'subsample': 0.8459582774430183, 'colsample_bytree': 0.6419511941734789, 'gamma': 0.5355389236566817, 'reg_alpha': 7.117722899928874e-07, 'reg_lambda': 5.1182398019437334e-05, 'min_child_weight': 7}\n",
      "  Trial 51: F1=0.0000, Accuracy=0.9500, Params={'n_estimators': 66, 'learning_rate': 0.12221081192954712, 'max_depth': 9, 'subsample': 0.6066377047895773, 'colsample_bytree': 0.689354237121635, 'gamma': 0.8426564287487066, 'reg_alpha': 89.04364264463771, 'reg_lambda': 0.0014087528111139261, 'min_child_weight': 5}\n",
      "  Trial 54: F1=0.1442, Accuracy=0.9229, Params={'n_estimators': 390, 'learning_rate': 0.00032389218257241356, 'max_depth': 5, 'subsample': 0.9034925049134748, 'colsample_bytree': 0.9681677864619868, 'gamma': 0.6209355460485576, 'reg_alpha': 0.012698514383229456, 'reg_lambda': 1.6560647160556892e-07, 'min_child_weight': 9}\n",
      "  Trial 57: F1=0.0000, Accuracy=0.9500, Params={'n_estimators': 66, 'learning_rate': 0.12221081192954712, 'max_depth': 7, 'subsample': 0.7654813824868525, 'colsample_bytree': 0.9113685851228608, 'gamma': 0.8426564287487066, 'reg_alpha': 89.04364264463771, 'reg_lambda': 19.98032230214516, 'min_child_weight': 10}\n",
      "  Trial 67: F1=0.0000, Accuracy=0.9500, Params={'n_estimators': 138, 'learning_rate': 0.03933147560571383, 'max_depth': 3, 'subsample': 0.5332136141001996, 'colsample_bytree': 0.5388753641135963, 'gamma': 0.2416888973912319, 'reg_alpha': 68.83245546889012, 'reg_lambda': 3.939326309372853e-07, 'min_child_weight': 2}\n",
      "  Trial 68: F1=0.0333, Accuracy=0.9443, Params={'n_estimators': 246, 'learning_rate': 0.018756609007875253, 'max_depth': 6, 'subsample': 0.7580595442584038, 'colsample_bytree': 0.7279925962532261, 'gamma': 0.7696178254351269, 'reg_alpha': 4.583630708733924e-08, 'reg_lambda': 84.70330158885163, 'min_child_weight': 3}\n",
      "  Trial 80: F1=0.0000, Accuracy=0.9500, Params={'n_estimators': 340, 'learning_rate': 0.028640158939658995, 'max_depth': 10, 'subsample': 0.5668080174054861, 'colsample_bytree': 0.7114880931202257, 'gamma': 0.7665788973647405, 'reg_alpha': 85.31006731295986, 'reg_lambda': 1.4713947472717473e-06, 'min_child_weight': 6}\n",
      "  Trial 89: F1=0.1270, Accuracy=0.9314, Params={'n_estimators': 428, 'learning_rate': 0.010464103617045483, 'max_depth': 3, 'subsample': 0.7954202306320902, 'colsample_bytree': 0.7824477412387172, 'gamma': 0.5552092249449411, 'reg_alpha': 0.0028279953712552885, 'reg_lambda': 0.00010426414192538399, 'min_child_weight': 2}\n",
      "  Trial 92: F1=0.0444, Accuracy=0.9414, Params={'n_estimators': 275, 'learning_rate': 0.005074351781638781, 'max_depth': 8, 'subsample': 0.8459582774430183, 'colsample_bytree': 0.6419511941734789, 'gamma': 0.5355389236566817, 'reg_alpha': 7.117722899928874e-07, 'reg_lambda': 5.1182398019437334e-05, 'min_child_weight': 7}\n",
      "  Trial 95: F1=0.0000, Accuracy=0.9500, Params={'n_estimators': 340, 'learning_rate': 0.05664527002521255, 'max_depth': 3, 'subsample': 0.8977972519520767, 'colsample_bytree': 0.7114880931202257, 'gamma': 0.8824128756240242, 'reg_alpha': 85.31006731295986, 'reg_lambda': 1.5302260148148015e-06, 'min_child_weight': 6}\n",
      "  Trial 97: F1=0.0889, Accuracy=0.9314, Params={'n_estimators': 253, 'learning_rate': 0.15820282261307023, 'max_depth': 10, 'subsample': 0.5668080174054861, 'colsample_bytree': 0.7296826075759877, 'gamma': 0.4128556103059402, 'reg_alpha': 4.443770900154847, 'reg_lambda': 2.28909120001162e-08, 'min_child_weight': 3}\n"
     ]
    }
   ],
   "source": [
    "def objective_xgb_tuned(trial):\n",
    "    # Parameter space for XGBoost\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'logloss',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 500),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-4, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 1e-8, 100.0, log=True),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 1e-8, 100.0, log=True),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'random_state': 42,\n",
    "    }\n",
    "\n",
    "    # use Pipelien to avoid leakage\n",
    "    pipeline = Pipeline([\n",
    "        ('smote', SMOTE(random_state=42)),\n",
    "        ('classifier', xgb.XGBClassifier(**params))\n",
    "    ])\n",
    "\n",
    "    # use cross validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scoring = {\n",
    "        'f1_score': make_scorer(f1_score, zero_division=0),\n",
    "        'accuracy': make_scorer(accuracy_score)\n",
    "    }\n",
    "\n",
    "    scores = cross_validate(pipeline, X_train, y_train, cv=skf, scoring=scoring)\n",
    "    \n",
    "    # defense if nan\n",
    "    mean_f1 = np.nanmean(scores['test_f1_score']) if np.any(np.isnan(scores['test_f1_score'])) else scores['test_f1_score'].mean()\n",
    "    mean_accuracy = np.nanmean(scores['test_accuracy']) if np.any(np.isnan(scores['test_accuracy'])) else scores['test_accuracy'].mean()\n",
    "\n",
    "    if np.isnan(mean_f1) or np.isnan(mean_accuracy):\n",
    "        return 0.0, 0.0\n",
    "    # Kembalikan rata-rata F1-Score dan Accuracy dari cross-validation\n",
    "    \n",
    "    return mean_f1, mean_accuracy\n",
    "\n",
    "# Maximize F1-Score and AUC\n",
    "study_xgb_tuned= optuna.create_study(directions=['maximize', 'maximize'])\n",
    "# Create study\n",
    "study_xgb_tuned.optimize(objective_xgb_tuned, n_trials=100)\n",
    "\n",
    "# save the experiment\n",
    "pareto_xgb_solution = study_xgb_tuned.best_trials\n",
    "\n",
    "print(\"\\n--- Multi-objective Tuning in XGBoost ---\")\n",
    "print(\"Pareto Optimal Solutions in XGBoost:\")\n",
    "for trial in pareto_xgb_solution:\n",
    "    print(f\"  Trial {trial.number}: F1={trial.values[0]:.4f}, Accuracy={trial.values[1]:.4f}, Params={trial.params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e07252",
   "metadata": {},
   "source": [
    "Hasil tuned XGBoost model yang terbaik ada dua yaknil trial ke-11 dan trial ke-54. Adapun, parameter yang akan dipilih adalah params di Trial-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7d111eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try to use params from Trial 11\n",
      "F1: 0.14415584415584415, Accuracy: 0.9228571428571428\n",
      "Params: {'n_estimators': 350, 'learning_rate': 0.001955587027306534, 'max_depth': 5, 'subsample': 0.9346413590938991, 'colsample_bytree': 0.935138120950715, 'gamma': 0.6209355460485576, 'reg_alpha': 1.2002869814885297, 'reg_lambda': 1.6560647160556892e-07, 'min_child_weight': 8}\n"
     ]
    }
   ],
   "source": [
    "# check params in trial 186\n",
    "if 11 < len(study_xgb_tuned.trials):\n",
    "    selected_trial_11 = study_xgb_tuned.trials[11]\n",
    "    \n",
    "    # store best params\n",
    "    best_params_xgb_tuned = selected_trial_11.params\n",
    "    best_f1_xgb_tuned = selected_trial_11.values[0]\n",
    "    best_accuracy_xgb_tuned = selected_trial_11.values[1]\n",
    "    \n",
    "    # print the result\n",
    "    print(f\"Try to use params from Trial {selected_trial_11.number}\")\n",
    "    print(f'F1: {best_f1_xgb_tuned}, Accuracy: {best_accuracy_xgb_tuned}')\n",
    "    print(f\"Params: {best_params_xgb_tuned}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a1d4dda5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Evaluasi Model XGB Tuned pada Validation Set:\n",
      "      Metric     Score\n",
      "0   Accuracy  0.926667\n",
      "1        AUC  0.330106\n",
      "2     Recall  0.000000\n",
      "3  Precision  0.000000\n",
      "4         F1  0.000000\n"
     ]
    }
   ],
   "source": [
    "# validation result\n",
    "# fit model with best_params_xgb_tuned\n",
    "best_xgb_model = xgb.XGBClassifier(**best_params_xgb_tuned)\n",
    "best_xgb_model.fit(X_train_SMOTE, y_train_SMOTE)\n",
    "\n",
    "# predict\n",
    "y_pred_valid = best_xgb_model.predict(X_valid)\n",
    "y_proba_valid = best_xgb_model.predict_proba(X_valid)[:, 1]\n",
    "\n",
    "# get all scores\n",
    "accuracy_valid = accuracy_score(y_valid, y_pred_valid)\n",
    "auc_valid = roc_auc_score(y_valid, y_proba_valid)\n",
    "recall_valid = recall_score(y_valid, y_pred_valid, zero_division=0)\n",
    "precision_valid = precision_score(y_valid, y_pred_valid, zero_division=0)\n",
    "f1_valid = f1_score(y_valid, y_pred_valid, zero_division=0)\n",
    "\n",
    "# create dataframe\n",
    "results_valid_best_params_xgb = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'AUC', 'Recall', 'Precision', 'F1'],\n",
    "    'Score': [accuracy_valid, auc_valid, recall_valid, precision_valid, f1_valid]\n",
    "})\n",
    "\n",
    "print(\"Hasil Evaluasi Model XGB Tuned pada Validation Set:\")\n",
    "print(results_valid_best_params_xgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5e12a2",
   "metadata": {},
   "source": [
    "Hasil masih overfitting dan meskipun sudah menggunakan params tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115a233f",
   "metadata": {},
   "source": [
    "# Evaluation on Final Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea25171f",
   "metadata": {},
   "source": [
    "## Recap\n",
    "\n",
    "Model Decision Tree (Data No SMOTE)\n",
    "\n",
    "| Metrik | CV on Training | Eval on Validation (Untuned) | Eval on set Validation (Tuned) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Accuracy** | 0.898571 | 0.920000 | 0.800000 |\n",
    "| **AUC** | 0.544154 | 0.485915 | 0.486796 |\n",
    "| **Recall** | 0.150000 | 0.000000 | 0.125000 |\n",
    "| **Precision** | 0.087222 | 0.000000 | 0.041667 |\n",
    "| **F1** | 0.109341 | 0.000000 | 0.062500 |\n",
    "\n",
    "Model XGBoost (Data SMOTE):\n",
    "\n",
    "| Metrik | CV on Training | Eval on Validation (Untuned) | Eval on set Validation (Tuned) |\n",
    "| :--- | :--- | :--- | :--- |\n",
    "| **Accuracy** | 0.914286 | 0.913333 | 0.926667 |\n",
    "| **AUC** | 0.556046 | 0.383803 | 0.330106 |\n",
    "| **Recall** | 0.100000 | 0.000000 | 0.000000 |\n",
    "| **Precision** | 0.078333 | 0.000000 | 0.000000 |\n",
    "| **F1** | 0.086905 | 0.000000 | 0.000000 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb0a41a",
   "metadata": {},
   "source": [
    "Dengan pertimabangan\n",
    "1. Model memiliki performa yang cukup baik di antara lainnya\n",
    "2. Data overfit dan susah mengenali pola yang tidak dilihat oleh model bisa jadi disebabkan karena data yang kurang fitur atau fitur terlalu umum, tidak memiliki pola yang bisa digeneralisasi, sehingga pemilihan model yang lebih simpel akan dilakukan\n",
    "\n",
    "Maka dari itu, dua poin di atas, model final akan dipilih sebagai final model adalah decision tree yang telah di-tuned. Hal ini karena model masih bisa menjaga akuras, sedikit lebih rendah mungkin karena tradeoff dengan metrik lain, namun hasil AUC, Recall, Precision, da F1 berhasil ditingkatkan pada evaluasi di set data validation. Walaupun, lagi-lagi ini nilai masih sangat rendah namun objektif meningkatkan performa dengan tuning tercapai. **Dengan kesadaran penuh, kami menyadari bahwa model masih perlu banyak diimprove baik dari segi data ataupun experimen lainnya.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9543e9c7",
   "metadata": {},
   "source": [
    "## Test on Set Data Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e1074227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil Evaluasi Model Decision Tree Final pada Test Set:\n",
      "      Metric     Score\n",
      "0   Accuracy  0.806667\n",
      "1        AUC  0.423077\n",
      "2     Recall  0.000000\n",
      "3  Precision  0.000000\n",
      "4         F1  0.000000\n"
     ]
    }
   ],
   "source": [
    "final_model = best_dt_model.fit(X_train, y_train)\n",
    "\n",
    "# predict on X_test\n",
    "y_pred_test = final_model.predict(X_test)\n",
    "y_proba_test = final_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# calculate score/metreics\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "auc_test = roc_auc_score(y_test, y_proba_test)\n",
    "recall_test = recall_score(y_test, y_pred_test, zero_division=0)\n",
    "precision_test = precision_score(y_test, y_pred_test, zero_division=0)\n",
    "f1_test = f1_score(y_test, y_pred_test, zero_division=0)\n",
    "\n",
    "# create dataframe\n",
    "results_test_final_dt = pd.DataFrame({\n",
    "    'Metric': ['Accuracy', 'AUC', 'Recall', 'Precision', 'F1'],\n",
    "    'Score': [accuracy_test, auc_test, recall_test, precision_test, f1_test]\n",
    "})\n",
    "\n",
    "print(\"Hasil Evaluasi Model Decision Tree Final pada Test Set:\")\n",
    "print(results_test_final_dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891d0da7",
   "metadata": {},
   "source": [
    "Seperti yang dijealskan sebelumnya, walaupun ada peningkatan tapi hasilnya masih sangat kurang. pada data test AUC ada penuruna sedikit dan ini umum terjadi pada banyak kasus. Dikarenakan nilainya sudah sangat rendah, utamanya pada Recall, precision, dan f1, maka hasil evaluasi dengan set test data hasilnya belum memuaskan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4132920d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.84      0.89       142\n",
      "           1       0.04      0.12      0.06         8\n",
      "\n",
      "    accuracy                           0.80       150\n",
      "   macro avg       0.49      0.48      0.48       150\n",
      "weighted avg       0.90      0.80      0.84       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred_valid_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "97948fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.89       143\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.81       150\n",
      "   macro avg       0.47      0.42      0.45       150\n",
      "weighted avg       0.90      0.81      0.85       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639e495",
   "metadata": {},
   "source": [
    "# Save Model and Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "90c70674",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump with .pkl\n",
    "utils.pickle_dump(final_model, config[\"production_model_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "43dd9e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil tuning Decision Tree berhasil disimpan ke dalam file: dt_tuned_params.json\n"
     ]
    }
   ],
   "source": [
    "# save documentation tuning wiht model decision tree\n",
    "results_dt = {\n",
    "    \"best_f1_score\": best_f1_dt_tuned,\n",
    "    \"best_accuracy\": best_accuracy_dt_tuned,\n",
    "    \"best_parameters\": best_params_dt_tuned\n",
    "}\n",
    "\n",
    "output_filepath_dt = 'dt_tuned_params.json'\n",
    "\n",
    "with open(output_filepath_dt, 'w') as json_file:\n",
    "    json.dump(results_dt, json_file, indent=4)\n",
    "\n",
    "print(f\"Hasil tuning Decision Tree berhasil disimpan ke dalam file: {output_filepath_dt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f91b61a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil tuning XGBoost berhasil disimpan ke dalam file: xgb_tuned_params.json\n"
     ]
    }
   ],
   "source": [
    "# save documentation tuning with model XGB\n",
    "results_xgb = {\n",
    "    \"best_f1_score\": best_f1_xgb_tuned,\n",
    "    \"best_accuracy\": best_accuracy_xgb_tuned,\n",
    "    \"best_parameters\": best_params_xgb_tuned\n",
    "}\n",
    "\n",
    "output_filepath_xgb = 'xgb_tuned_params.json'\n",
    "\n",
    "with open(output_filepath_xgb, 'w') as json_file:\n",
    "    json.dump(results_xgb, json_file, indent=4)\n",
    "\n",
    "print(f\"Hasil tuning XGBoost berhasil disimpan ke dalam file: {output_filepath_xgb}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc32ee49",
   "metadata": {},
   "source": [
    "**untuk re-run atua pengecekan sebaiknya menggunakan params yang sudah di save dalam json ini saja. ini menghindari adanya object yang dibuat optuna yang mungkin berbeda kombinasinya. Jadi saat fit paramater bisa menggunakan inputan yanga ada dalam json**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6f336dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "test_model = utils.pickle_load('models/dt_model_selected.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8f18e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_validating_model = test_model.predict(X_valid)\n",
    "y_pred_testing_model = test_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0da14475",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.85      0.89       142\n",
      "           1       0.04      0.12      0.06         8\n",
      "\n",
      "    accuracy                           0.81       150\n",
      "   macro avg       0.49      0.49      0.48       150\n",
      "weighted avg       0.90      0.81      0.85       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_valid, y_pred_validating_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "db1d3607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.89       143\n",
      "           1       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.81       150\n",
      "   macro avg       0.47      0.42      0.45       150\n",
      "weighted avg       0.90      0.81      0.85       150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_testing_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b15eb",
   "metadata": {},
   "source": [
    "Hasilnya sama dengan sebelumnya dan berarti model yang disimpan sudah tepat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fraud_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
