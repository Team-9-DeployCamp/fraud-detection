# Fraud Detection Project

## ğŸ” Overview
This project implements a machine learning-based fraud detection system with a REST API for real-time predictions.

## ğŸ“ Project Structure
```
fraud_detection/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train_model.py      # Model training script
â”‚   â”œâ”€â”€ inference.py        # Prediction logic
â”‚   â”œâ”€â”€ api.py             # FastAPI REST API
â”‚   â””â”€â”€ util.py            # Utility functions
â”œâ”€â”€ models/                 # Trained models (created after training)
â”œâ”€â”€ dataset/               # Data files
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml        # Configuration file
â”œâ”€â”€ notebooks/             # Jupyter notebooks for EDA
â”œâ”€â”€ run_pipeline.py        # Main pipeline script
â”œâ”€â”€ test_api.py           # API testing script
â””â”€â”€ requirements_api.txt   # Python dependencies
```

## ğŸš€ Quick Start

### 1. Install Dependencies
```bash
python run_pipeline.py install
```

### 2. Train Model
```bash
python run_pipeline.py train
```

### 3. Start API Server
```bash
python run_pipeline.py api
```

### 4. Run Everything (Install + Train + API)
```bash
python run_pipeline.py full
```

## ğŸ“¡ API Endpoints

### Health Check
```bash
GET http://127.0.0.1:8000/health
```

### Single Prediction
```bash
POST http://127.0.0.1:8000/predict
Content-Type: application/json

{
    "amount": 150.50,
    "merchant_type": "electronics",
    "device_type": "mobile"
}
```

### Batch Prediction
```bash
POST http://127.0.0.1:8000/predict_batch
Content-Type: application/json

{
    "transactions": [
        {"amount": 50.25, "merchant_type": "groceries", "device_type": "mobile"},
        {"amount": 1000.00, "merchant_type": "electronics", "device_type": "desktop"}
    ]
}
```

## ğŸ§ª Testing

### Test API (run this in a separate terminal while API is running)
```bash
python test_api.py
```

### Interactive API Documentation
Once the API is running, visit:
- Swagger UI: http://127.0.0.1:8000/docs
- ReDoc: http://127.0.0.1:8000/redoc

## ğŸ”§ Configuration

Edit `config/config.yaml` to modify:
- Data paths
- Model parameters
- API settings (host, port)

## ğŸ“Š Model Information

The system trains baseline models:
- **Logistic Regression**: Fast, interpretable
- **Random Forest**: More complex, potentially better performance

The best performing model (based on ROC-AUC) is automatically selected and saved.

## ğŸ›¡ï¸ Fraud Detection Features

- **Real-time predictions**: Single transaction analysis
- **Batch processing**: Multiple transactions at once
- **Risk levels**: Low, Medium, High risk classification
- **Probability scores**: Fraud likelihood (0-1)
- **Model info**: Get details about the loaded model

## ğŸ“ˆ Response Format

```json
{
    "is_fraud": false,
    "fraud_probability": 0.234,
    "risk_level": "Low",
    "transaction_details": {
        "amount": 150.50,
        "merchant_type": "electronics",
        "device_type": "mobile"
    }
}
```

## ğŸ”„ Pipeline Commands

| Command | Description |
|---------|-------------|
| `python run_pipeline.py install` | Install required packages |
| `python run_pipeline.py train` | Train the fraud detection model |
| `python run_pipeline.py test` | Test the inference module |
| `python run_pipeline.py api` | Start the API server |
| `python run_pipeline.py full` | Run complete pipeline |

## ğŸš¨ Troubleshooting

### Model Not Found Error
- Make sure to run training first: `python run_pipeline.py train`

### API Connection Error
- Check if API is running: `python run_pipeline.py api`
- Verify port 8000 is not in use

### Package Import Errors
- Install dependencies: `python run_pipeline.py install`
- Or manually: `pip install -r requirements_api.txt`

## ğŸ“ Development Notes

- The model handles unknown categories gracefully
- All categorical features are automatically encoded
- The API includes comprehensive error handling
- Logging and debugging information is available

## ğŸ¯ Next Steps

1. **Model Improvement**: 
   - Feature engineering
   - Hyperparameter tuning
   - Advanced algorithms (XGBoost, Neural Networks)

2. **Production Deployment**:
   - Docker containerization
   - Cloud deployment (AWS, GCP, Azure)
   - Load balancing and scaling

3. **Monitoring**:
   - Model performance tracking
   - Data drift detection
   - Real-time alerts
